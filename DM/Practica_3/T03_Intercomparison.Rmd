---
title: "Tarea 3. Técnicas de aprendizaje supervisado"
output:
  html_document:
    df_print: paged
---

## Minería de Datos (Master en Data Science, UIMP-UC)
### [Estudiante: David Montero Loaiza]

```{r}
require(caret)
require(tree)
require(randomForest)
require(FNN)
```

#### 1 Conjunto de datos meteo

Comenzaremos cargando el dataset meteo, que ya ha sido utilizado en sesiones anteriores.

```{r}
load("C:/Users/Dave Mont/Desktop/Master_of_DataScience/Data_Mining/Practica_3/meteo.RData")
```

Como ya sabéis, la variable objetivo en este dataset es la precipitation diaria en Lisboa durante el período 1979-2008, y para modelizar ésta se dispone de un conjunto de 8 variables meteorológicas predictoras que describen la circulación de larga escala definidas sobre un dominio geográfico que incluye 40 puntos sobre la Península Ibérica. (en total 8×40=320 variables explicativas). Las variables predictoras son:

- altura geopotencial en 500 hPa (Z500)
- temperatura del aire en los niveles 850 hPa, 700 hPa y 500 hPa (ta850, ta700 y ta500), y en superficie (tas)
- humedad específica del aire en 850 hPa y 500 hPa (hus850, hus500)
- presión a nivel del mar (psl)

Para agilizar los tiempos de cómputo, reduciremos la dimensionalidad del problema. Como ya se ha visto en sesiones anteriores, una alternativa para tal fin es el uso de PCs. Sin embargo, para no limitar la interpretabilidad de los resultados obtenidos con árboles, utilizaremos otra aproximación aquí. En concreto, optaremos por un análisis de correlaciones, en el que se calcula la correlación de Spearman entre nuestra variable objetivo y todas las variables predictoras disponibles.

```{r}
correlations = cor(x,y,method = "spearman")
```

La asunción de partida es que cuanto más fuerte sea esta correlación, mayor es el vínculo físico entre predictando y predictor, y por tanto, más útil es la información que nos aporta ese predictor. Por tanto, este análisis nos permite descartar predictores poco relevantes. Siguiendo esta idea, calcularemos la correlación existente entre nuestro predictando y los 320 predictores, y eliminaremos aquellos con correlaciones entre -0.4 y 0.4. ¿Cuánto se ha reducido la dimensionalidad del problema?

```{r}
goodpredictors = !(correlations <= 0.4 & correlations >= -0.4)

sum(goodpredictors)
```

La dimensionalidad del problema se redujo de 320 variables predictoras a un total de 37 predictores.

Para simplificar aún más los cálculos, nos limitaremos a los primeros 5000 días del dataset. Como siempre, consideraremos una partición de la muestra en dos subconjuntos independientes, train y test, escogidos aleatoriamente (75% para entrenar y 25% para validar).

```{r}
set.seed(1234)

X = x[1:5000,goodpredictors]
y = y[1:5000]

trainIdx = createDataPartition(y,p = 0.75,list = FALSE)

Xtrain = X[trainIdx,]
Xtest = X[-trainIdx,]

ytrain = y[trainIdx]
ytest = y[-trainIdx]
```

#### 2 Árboles de clasificación y regresión (2.5 puntos)

Como ya hemos visto en sesiones anteriores, tendremos que crear dos modelos independientes, uno para la clasificación del evento binario lluvia/no lluvia y otro para el evento continuo cantidad de lluvia. Nos centramos en primer lugar en la clasificación lluvia/no lluvia. Para ello, tenemos que crear la variable binaria ocurrencia de precipitación (considera un umbral de 1 mm) y construir el dataframe asociado al problema.

```{r}
bin_ytrain = as.numeric(ytrain > 1)
bin_ytest = as.numeric(ytest > 1)

trainDataOc = data.frame(y = bin_ytrain,Xtrain)
testDataOc = data.frame(y = bin_ytest,Xtest)
```

A continuación construiremos el árbol completo (usa la función tree). ¿Cuántos nodos terminales obtienes? ¿Qué variables predictoras dan lugar a las primeras subdivisiones del árbol?

```{r}
set.seed(1234)

completeTree = tree(y ~ .,
                    trainDataOc,
                    split = "deviance",
                    control = tree.control(nrow(trainDataOc),mincut = 1,minsize = 2,mindev = 0))

plot(completeTree)
text(completeTree)

sumTree = summary(completeTree)

paste("cantidad de nodos terminales:",sumTree$size)
paste("Variables predictoras de las primeras subdivisiones:")
head(completeTree$frame$var)
```

Para simplificar este árbol tan complejo tendremos que podarlo adecuadamente. Utiliza una cross-validación con un 10-fold para encontrar el número de nodos terminales del árbol óptimo. ¿Cuál es este número? ¿Qué predictores aparecen como los más importantes?

```{r}
set.seed(1234)

# EL k = 10 YA SE ENCUENTRA POR DEFECTO EN LA FUNCION
k10tree = cv.tree(completeTree)

plot(k10tree,xlim = c(1,10))
```

Con 6 nodos terminales el árbol ya es óptimo.

```{r}
prunedTree = prune.tree(completeTree,best = 6)

plot(prunedTree)
text(prunedTree)

sumTree = summary(prunedTree)

paste("cantidad de nodos terminales:",sumTree$size)
paste("Variables predictoras de las primeras subdivisiones:")
head(prunedTree$frame$var)
```

Utiliza este árbol óptimo para predecir en el test. Guarda las predicciones.

```{r}
bin_predTree = predict(prunedTree,newdata = testDataOc)
```

Una vez obtenidas las predicciones de ocurrencia pasaremos a estimar la cantidad de precipitación. Primero creamos el dataset correspondiente.

```{r}
trainDataCa = data.frame(y = ytrain,Xtrain)
testDataCa = data.frame(y = ytest,Xtest)
```

A continuación construiremos dos árboles, uno entrenado sobre todo el conjunto de train y otro entrenado sólo sobre los días de lluvia (en el train). Empezamos por el primero de estos árboles. Construye el árbol completo ¿Cuántos nodos terminales obtienes? ¿Qué variables predictoras dan lugar a las primeras subdivisiones del árbol? ¿Son las mismas que para el caso de la ocurrencia?

```{r}
set.seed(1234)

completeTree = tree(y ~ .,
                    trainDataCa,
                    split = "deviance",
                    control = tree.control(nrow(trainDataCa),mincut = 1,minsize = 2,mindev = 0))

plot(completeTree)
text(completeTree)

sumTree = summary(completeTree)

paste("cantidad de nodos terminales:",sumTree$size)
paste("Variables predictoras de las primeras subdivisiones:")
head(completeTree$frame$var)
```

Al igual que hicimos para el caso de la ocurrencia, tendremos que podar este árbol tan complejo. Utiliza una cross-validación con un 10-fold para encontrar el número de nodos terminales del árbol óptimo. ¿Cuál es este número? ¿Qué predictores aparecen como los más importantes?

```{r}
set.seed(1234)

k10tree = cv.tree(completeTree)

plot(k10tree,xlim = c(1,10))
```

Con 3 nodos terminales el árbol ya es óptimo.

```{r}
prunedTree = prune.tree(completeTree,best = 3)

plot(prunedTree)
text(prunedTree)

sumTree = summary(prunedTree)

paste("cantidad de nodos terminales:",sumTree$size)
paste("Variables predictoras de las primeras subdivisiones:")
head(prunedTree$frame$var)
```

Utiliza el árbol óptimo que acabas de encontrar para predecir en el test, y conserva la predicción obtenida

```{r}
reg_predTree1 = predict(prunedTree,newdata = testDataCa)
```

Repite el mismo proceso para el segundo árbol de regresión (el que sólo se entrena sobre los días de lluvia en el train).

```{r}
set.seed(1234)

completeTree = tree(y ~ .,
                    trainDataCa,
                    subset = y > 0,
                    split = "deviance",
                    control = tree.control(nrow(trainDataCa[trainDataCa$y > 0,]),mincut = 1,minsize = 2,mindev = 0))

plot(completeTree)
text(completeTree)

sumTree = summary(completeTree)

paste("cantidad de nodos terminales:",sumTree$size)
paste("Variables predictoras de las primeras subdivisiones:")
head(completeTree$frame$var)
```

```{r}
set.seed(1234)

k10tree = cv.tree(completeTree)

plot(k10tree,xlim = c(1,10))
```

Según el gráfico, con un nodo terminal el árbol sería óptimo, pero al no haber divisiones, se usarán 2.

```{r}
prunedTree = prune.tree(completeTree,best = 2)

plot(prunedTree)
text(prunedTree)

sumTree = summary(prunedTree)

paste("cantidad de nodos terminales:",sumTree$size)
paste("Variables predictoras de las primeras subdivisiones:")
head(prunedTree$frame$var)
```

```{r}
reg_predTree2 = predict(prunedTree,newdata = testDataCa[testDataCa$y > 0,])
```

Obtén las dos series predichas completas para el test (la secuencia lluvia/no lluvia será la misma en las dos) y valida tus resultados en función de las siguiente métricas:

Para la parte binaria lluvia/no lluvia: Accuracy.

```{r}
confusionMatrix(as.factor(as.numeric(bin_predTree > 0.5)),as.factor(testDataOc$y))
```

El accuracy es de un 86.31%.

Para la serie completa: RMSE, correlación de Spearman y ratio de varianzas.

```{r}
RMSEs = c(RMSE(reg_predTree1,testDataCa$y),
          RMSE(reg_predTree2,testDataCa$y[testDataCa$y > 0]))

cors = c(cor(reg_predTree1,testDataCa$y,method = "spearman"),
         cor(reg_predTree2,testDataCa$y[testDataCa$y > 0],method = "spearman"))

rvs = c(var(reg_predTree1)/var(testDataCa$y),
        var(reg_predTree2)/var(testDataCa$y[testDataCa$y > 0]))

treeResults = data.frame(Desc = c("Todos los dias (CART)","Dias de lluvia (CART)"),
                         RMSE = RMSEs,
                         Spearman = cors,
                         Var.ratio = rvs)

treeResults
```

Pregunta: ¿Cuál de los dos árboles da mejores resultados? ¿Por qué?

Teniendo en cuenta los resultados obtenidos, el primer árbol es el que da mejores resultados ya que tiene un RMSE menos con una mayor correlación de Spearman y un mayor Ratio de Varianza.

#### 3 Random forests (2.5 puntos)

A continuación vamos a realizar el mismo ejercicio pero sustituyendo árboles individuales por random forests, empleando para ello en este ejercicio la técnica de “bagging”. Empecemos con el evento ocurrencia. Para estimar cuál sería el tamaño óptimo de nuestro random forest, prueba bosques de hasta 1000 árboles (utiliza la función randomForest) y plotea los errores “Out-Of-Bag” (OOB). ¿Con cuántos árboles te quedarías?

Nota: Hemos visto en la teoría que además del número de árboles, el otro parámetro a ajustar en los random forests es el número de predictores que se consideran en cada nodo para el splitting. En este ejemplo utlizaremos los valores típicos; √n en problemas de clasificación y n/3 en problemas de predicción (siendo n el número total de predictores disponibles).

```{r}
set.seed(1234)

# EL mrty DE LA NOTA YA SE ENCUENTRA POR DEFECTO EN LA FUNCION
rf = randomForest(as.factor(y) ~ .,data = trainDataOc,ntree = 1000)
```

```{r}
plot(rf$err.rate[,1],ylab = "OOB",xlab = "N Trees",main = "OOB Error",type = "l")
```

Observando el gráfico de errores, el mínimo se encontraría al rededor de los 100 árboles.

```{r}
ntree = which(rf$err.rate[,1] == min(rf$err.rate[,1]))

paste("Número de árboles óptimo:",ntree)
```

Utiliza el bosque de tamaño óptimo parar predecir la ocurrencia en el test, y conserva la predicción.

```{r}
set.seed(1234)

rf = randomForest(as.factor(y) ~ .,data = trainDataOc,ntree = ntree)

bin_predRF = predict(rf,newdata = testDataOc)
```

Seguidamente, tal y como hicimos con los árboles individuales, vamos a crear dos random forests para la cantidad, uno que se entrene sobre todo el dataset de train y otro que se entrene sólo sobre los días de lluvia (en el train). De nuevo, tendrás que estimar cuál es el número óptimo de árboles en cada uno de ellos (prueba bosques de hasta 1000 árboles). ¿Qué tamaños óptimos obtienes?

```{r}
set.seed(1234)

rf1 = randomForest(y ~ .,data = trainDataCa,ntree = 1000)
rf2 = randomForest(y ~ .,data = trainDataCa,ntree = 1000,subset = y > 0)
```

```{r}
plot(rf1$mse,ylab = "MSE",xlab = "N Trees",main = "MSE Error",type = "l")
plot(rf2$mse,ylab = "MSE",xlab = "N Trees",main = "MSE Error",type = "l")
```

```{r}
ntree1 = which(rf1$mse == min(rf1$mse))
ntree2 = which(rf2$mse == min(rf2$mse))

paste("Número de árboles óptimo para todos los días:",ntree1)
paste("Número de árboles óptimo para los días con lluvia:",ntree2)
```

Utiliza los bosques óptimos encontrados para predecir la cantidad en el test, y conserva las predicciones obtenidas.

```{r}
set.seed(1234)

rf1 = randomForest(y ~ .,data = trainDataCa,ntree = ntree1)
rf2 = randomForest(y ~ .,data = trainDataCa,ntree = ntree2,subset = y > 0)

reg_predRF1 = predict(rf1,newdata = testDataCa)
reg_predRF2 = predict(rf2,newdata = testDataCa[testDataCa$y > 0,])
```

Construye las predicciones completas (ocurrencia×cantidad) de test y valídalas en función de las mismas métricas utilizadas en el apartado anterior.

```{r}
confusionMatrix(as.factor(bin_predRF),as.factor(testDataOc$y))
```

El accuracy es de un 87.35%.

```{r}
RMSEs = c(RMSE(reg_predRF1,testDataCa$y),
          RMSE(reg_predRF2,testDataCa$y[testDataCa$y > 0]))

cors = c(cor(reg_predRF1,testDataCa$y,method = "spearman"),
         cor(reg_predRF2,testDataCa$y[testDataCa$y > 0],method = "spearman"))

rvs = c(var(reg_predRF1)/var(testDataCa$y),
        var(reg_predRF2)/var(testDataCa$y[testDataCa$y > 0]))

rfResults = data.frame(Desc = c("Todos los dias (Random Forest)","Dias de lluvia (Random Forest)"),
                         RMSE = RMSEs,
                         Spearman = cors,
                         Var.ratio = rvs)

rfResults
```

Pregunta: Compara estos resultados con los obtenidos para árboles individuales. ¿Qué conclusiones obtienes de la comparación entre árboles individuales y random forests?

```{r}
rbind(treeResults,rfResults)
```

Teniendo en cuenta los resultados obtenidos, no hay una gran diferencia entre ambos métodos, aunque si bien el RandomForest es ligeramente mejor que CART tanto en clasificación como en regresión y esto se ve representado en la correlación de Spearman y el Ratio de Varianza, aunque los RMSE no hayan disminuido mucho. 

#### 4 Modelos lineales generalizados (GLMs) (1.5 puntos)

Usaremos a continuación GLMs para el mismo problema abordado en los apartados anteriores. Como ya hemos visto en otras sesiones, debemos utilizar la familia binomial con función de enlace logit (regresión logística) para clasificación y la familia Gamma con función de enlace logarítmica para la cantidad.

Comenzamos con el modelo para la ocurrencia.

```{r}
glmModel = glm(y ~ .,data = trainDataOc,family = binomial)
```

Una vez tenemos el modelo, lo utilizamos para predecir en el test. Tendremos que convertir la predicción probabilística obtenida en binaria (considera un umbral 0.5).

```{r}
bin_predGLM = as.numeric(predict(glmModel,newdata = testDataOc) > 0.5)
```

A continuación, ajustamos el modelo de cantidad. Para ello tenemos que seleccionar previamente los días de lluvia (la familia Gamma sólo acepta valores positivos).

```{r}
glmModelCa = glm(y ~ .,data = trainDataCa,family = Gamma("log"),subset = y > 0)
```

Utilizamos el modelo obtenido para predecir la cantidad en el test.

```{r}
reg_predGLM = predict(glmModelCa,newdata = testDataCa[testDataCa$y > 0,])
```

De nuevo, multiplicamos la ocurrencia por la cantidad para obtener la predicción completa en el test y la validamos en función de las métricas de validación que utilizamos para CART y random forests.

```{r}
confusionMatrix(as.factor(bin_predGLM),as.factor(testDataOc$y))
```

El accuracy es de un 87.19%.

```{r}
RMSEs = RMSE(reg_predGLM,testDataCa$y[testDataCa$y > 0])

cors = cor(reg_predGLM,testDataCa$y[testDataCa$y > 0],method = "spearman")

rvs = var(reg_predGLM)/var(testDataCa$y[testDataCa$y > 0])

glmResults = data.frame(Desc = "Dias de lluvia (GLM)",
                         RMSE = RMSEs,
                         Spearman = cors,
                         Var.ratio = rvs)

glmResults
```

Pregunta: Compara estos resultados con los obtenidos para CART y random forests. ¿Qué conclusiones obtienes?

```{r}
rbind(treeResults,rfResults,glmResults)
```

El GLM no se comporta mejor que CART o RandomForest en cuestión de error (RMSE), ya que este aumenta, aunque aumente ligeramente en la correlación de Spearman.

#### 5 k nearest neighbors (k-NN) (1.5 puntos)

La última de las técnicas a utilizar será vecinos cercanos (ten en cuenta que en este caso ya no tendremos que predecir por separado ocurrencia y cantidad). Comenzaremos por una versión de k-NN en la que sólo se considere el vecino más cercano (utiliza la función knn.reg del paquete FNN).

Nota: Recuerda que en la técnica k-NN es muy importante pre-procesar adecuadamente (estandarizar) los predictores.

```{r}
reg_predKNN1 = knn.reg(scale(trainDataCa[,-1]),scale(testDataCa[,-1]),trainDataCa$y,k = 1)$pred
```

Como vimos en su día, el único parámetro a ajustar en la técnica k-NN es k (número de vecinos). Utilizaremos el paquete caret para encontrar el k óptimo en nuestro problema. Para ello, considera una cross-validación con 10 folds sobre el dataset de train y barre todos los k impares desde 1 a 50.

```{r}
ctrl = trainControl("cv",10)

knnModel = train(y ~ .,
                 data = trainDataCa,
                 method = "knn",
                 trControl = ctrl,
                 preProcess = c("center","scale"),
                 tuneGrid = expand.grid(k = seq(1,50,2)))
```

```{r}
knnModel$bestTune
```

Un k = 41 es el k óptimo para el modelo.

Utiliza este k óptimo para predecir en el test.

```{r}
reg_predKNN2 = predict(knnModel,newdata = testDataCa)
```

Valida las dos predicciones (con k=1 y con k=óptimo) en el test, en función de las medidas que se han ido utilizando en los apartados anteriores.

```{r}
RMSEs = c(RMSE(reg_predKNN1,testDataCa$y),
          RMSE(reg_predKNN2,testDataCa$y))

cors = c(cor(reg_predKNN1,testDataCa$y,method = "spearman"),
         cor(reg_predKNN2,testDataCa$y,method = "spearman"))

rvs = c(var(reg_predKNN1)/var(testDataCa$y),
        var(reg_predKNN2)/var(testDataCa$y))

knnResults = data.frame(Desc = c("Todos los dias (KNN k = 1)","Todos los dias (KNN k óptimo)"),
                         RMSE = RMSEs,
                         Spearman = cors,
                         Var.ratio = rvs)

knnResults
```

Pregunta: ¿Qué diferencias obtienes entre las dos versiones utilizadas de la técnica k-NN? ¿A qué se deben?

El error disminuye con el k óptimo, esto se debe a que con k = 1 el modelo tiende a sobreajustarse, aumentando el k se generaliza, se disminuye por lo tanto el error y aumenta la correlación.

#### 6 Conclusiones generales (2 puntos)

A la vista de los resultados obtenidos, argumenta razonadamente qué técnica o técnicas serían las mejores para la predicción de lluvia en Lisboa. Justifica tu respuesta.

```{r}
rbind(treeResults,rfResults,glmResults,knnResults)
```

Los modelos de RandomForest y de KNN óptimo obtuvieron los menores errores y las correlaciones más altas, aunque RandomForest obtuvo un mayor Ratio de Varianza que el de KNN óptimo. Teniendo en cuenta que se redujo la dimensionalidad, RandomForest puede ser un método apropiado para predecir la lluvia, aunque KNN sea un algoritmo menos complejo y que da resultados muy similares a los de RandomForest. En tercer lugar se podría usar CART para predecir la lluvia, con un error ligeramente más alto que el de KNN óptimo y una correlación ligeramente más baja.

En el caso de predecir sólo días de lluvia, los modelos obtuvieron errores mucho más altos que si modelaramos todos los días. En este caso, el GLM resultó ser el peor modelo con el error más alto de todos y el Ratio de Varianza más bajo, aunque la correlación más baja la obtuvo CART.