---
title: "Tarea 1. Variables Categóricas: Reglas de Asociación y Árboles de Clasificación"
output:
  html_document:
    df_print: paged
---

## Minería de Datos (Master en Data Science, UIMP-UC)
### [Profesores: Sixto Herrera y Rodrigo García]
### [Estudiante: David Montero Loaiza]

En la presente tarea consideraremos el dataset `Mushroom`, incluido tanto en la La librería [arulesViz](https://cran.r-project.org/web/packages/arulesViz/arulesViz.pdf) como en las diferentes plataformas descritas en el marco de la asignatura y en el GitHub dedicado a este Máster ([Mushroom](https://github.com/SantanderMetGroup/Master-Data-Science/blob/master/Data_mining/datasets/mushrooms.csv.)), para aplicar las diferentes técnicas vistas en el curso para variables categóricas: Reglas de Asociación y Árboles de Clasificación.

Para el desarrollo de la tarea se permitirá el uso de todo el material incluido en el Moodle de las asignatura así como el desarrollado por el alumno durante la realización de las prácticas.

La entrega consisitirá de un notebook de Jupyter ó un R-MarkDown, junto con el archivo html que éste genera. Ambos ficheros se entregarán a través del Moodle de la asignatura en la tarea correspondiente.

### Punto 1 (3 puntos):

Considerar uno de los algoritmos de asociación vistos en clase y obtener las reglas representativas del dataset fijando los parámetros de aprendizaje (soporte, confianza, etc...). Analizar los resultados en términos generales.

NOTA: Usar soportes superiores a 0.1 para evitar problemas de memoria.

```{r}
require(arulesViz)
```

```{r}
data("Mushroom")
```

```{r}
# ALGORITMO APRIORI CON SOPORTE IGUAL A 0.1 Y CONFIANZA 0.75
rules = apriori(Mushroom,parameter = list(support = 0.1,confidence = 0.75))
```

* ¿Cuantas reglas se han generado?

```{r}
# REGLAS DE ASOCIACION
rules
```

Se generarnon un total de 2'172.753 reglas de asociación.

* ¿Existe alguna regla redundante?, ¿Cuántas?

```{r}
# LOCICAL DE REGLAS REDINDANTES
red_rules = is.redundant(rules)

# LA SUMA NOS DA EL TOTAL DE REGLAS REDUNDANTES
paste("Hay un total de",sum(red_rules),"reglas redundantes")

# SE EXTRAE UN NUEVO SET DE REGLAS SIN REGLAS REDUNDANTES
notred_rules = rules[!red_rules]
notred_rules
```

El set de reglas, omitiendo las reglas redundantes, se reduce a un total de 8.803 reglas.

* ¿Existe alguna regla que incluya la variable objetivo: `Class=edible` ó `Class=poisonous`?, ¿Cuantas?

```{r}
# CLASES OBJETIVO
targets = c("Class=edible","Class=poisonous")

# CHEQUEAR SI LAS CLASES OBJETIVO ESTAN EN EL CONSECUENTE
check_rhs = notred_rules@rhs %in% targets 

# CHEQUEAR SI LAS CLASES OBJETIVO ESTAN EN EL ANTECEDENTE
check_lhs = notred_rules@lhs %in% targets

# CHEQUEAR SI LAS CLASES OBJETIVO ESTAN EN EL CONSECUENTE O EN EL ANTECEDENTE
targ_rules = notred_rules[check_rhs | check_lhs]
targ_rules
```

Existen, del set de reglas no redundantes, un total de 2.712 reglas que contienen las clases objetivo en el antecedente o en el consecuente.

* De cara a ser utilizada como modelo predictivo es adecuado que la variable objetivo se encuentre en el consecuente de la regla de asociación, ¿se da esta propiedad en alguna regla?

```{r}
# CHEQUEAR SI LAS CLASES OBJETIVO ESTAN EN EL CONSECUENTE
cons_rules = notred_rules[check_rhs]
cons_rules
```

Existen, del set de reglas no redundantes, un total de 588 reglas que contienen las clases objetivo en el consecuente.

* Considerar los subconjuntos de reglas con ambas clases como consecuente e ilustrar las variables implicadas en cada caso. Considerar alguno de los grafos vistos para apoyar las conclusiones obtenidas.

```{r}
plot(cons_rules,method = "paracoord")
```

### Punto 2 (4 puntos):

En este apartado aplicaremos árboles de clasificación para obtener un modelo que permita clasificar una nueva entrada. Para ello, vamos a utilizaremos el paquete `CaReT`. Este paquete (y los demás que hemos visto para trabajar con árboles en `R`) no aceptan objetos del tipo `transactions` como los del apartado anterior. Por tanto, hemos preparado un fichero *csv* con el dataset *Mushrooms*; puedes descargarlo desde esta aquí:
https://github.com/SantanderMetGroup/Master-Data-Science/tree/master/Data_mining/datasets. Lee el dataset con la función `read.csv`.

```{r}
require(caret)
require(rattle)
```

```{r}
# LEEMOS EL DATASET
df = read.csv(url("https://raw.githubusercontent.com/SantanderMetGroup/Master-Data-Science/master/Data_mining/datasets/mushrooms.csv"))
```

Ahora ya tenemos un data.frame con el que podemos empezar a trabajar. En primer lugar tendremos que eliminar la columna 17 (`veil.type`), ya que contiene un único nivel y daría errores en `CaReT`(esta columna podría eliminarse también en el caso de las reglas de asociación ya que no aporta información al dataset).

```{r}
# ELIMINAMOS LA COLUMNA 17
df = df[,-17]
```

Nuestro objetivo será encontrar la configuración (profundidad) óptima del árbol. Para ello, partiremos el dataset en dos subconjuntos indpendedientes de train y test (75% y 25% del total, respectivamente).

```{r}
# SEMILLA
set.seed(666)

# INDICE PARA TRAIN, PARTIENDO 75% PARA ENTRENAR
trainIndex = createDataPartition(df$class,p = 0.75,list = FALSE,times = 1)

# DATASET DE ENTRENAMIENTO
train = df[trainIndex,]

# DATASET DE TEST
test = df[-trainIndex,]

# VALORES VERDADEROS DE TEST
truth = test[,1]
```

Sobre el dataset de train, aplicaremos una cross-validación con 3 folds y la repetiremos 50 veces (recuerda que los árboles son sensibles a la partición train/test que se considere). 

```{r}
# CONTROL PARA ENTRENAMIENTO
# VALIDACION CRUZADA DE 3 FOLDS CON 50 REPETICIONES
ctrl = trainControl(method = "repeatedcv",number = 3,repeats = 50)

# ENTRENAMIENTO CON TODAS LAS VARIABLES
modAll = train(class ~ .,
            data = train,
            method = "rpart2",
            trControl = ctrl,
            tuneLength = 10)
```

* ¿Cuál es la configuración óptima del árbol? ¿Hay alguna diferencia entre el árbol *completo* y el óptimo? ¿Por qué crees que ocurre esto?

```{r}
# GRAFICAR PRECISION
plot(modAll)
```

```{r}
# ARBOL OPTIMO
modAll$bestTune
```

En este caso Caret entrenó árboles con profundidades variando desde 1 hasta 11, el árbol óptimo fue de una profundidad de tamaño 7. Este árbol óptimo ya había alcanzado una precisión en su proceso de validación mayor al 98%, el resto de árboles con profundidades mayores no supera en gran medida la precisión alcanzada.

```{r}
# ARBOL FINAL
fancyRpartPlot(modAll$finalModel)
```

* ¿Cuáles son las dos variables que mayor peso tienen a la hora de clasificar? Entrena un nuevo árbol considerando como predictores únicamente esas dos variables. ¿Qué resultados obtienes? 

```{r}
# VARIABLES EN ORDEN DE IMPORTANCIA
impVar = varImp(modAll)

# GRAFICAR LAS 10 MEJORES VARIABLES
plot(impVar,top = 10)
```

En este caso las variables de `odor` y `ring.type` hacen parte de las más importantes en el modelo.

```{r}
# MODELO CON LAS VARIABLES ODOR Y RING.TYPE
modBest = train(class ~ odor + ring.type,
            data = train,
            method = "rpart2",
            trControl = ctrl)
```

```{r}
# GRAFICAR PRECISION
plot(modBest)
```

```{r}
# ARBOL OPTIMO
modBest$bestTune
```

Utilizando solamente las dos variables con mayor importancia, el árbol óptimo, con una profundidad de tamaño 6, alcanza, al igual que el árbol óptimo utilizando todas las variables, una precisión en su proceso de validación superior al 98%. En este caso es una mejor opción utilizar el árbol óptimo con sólo estas dos variables, ya que con menos dimensiones se alcanza el mismo nivel de precisión.

```{r}
# ARBOL FINAL
fancyRpartPlot(modBest$finalModel)
```

* Entrena un nuevo árbol considerando como predictores cualesquiera otras dos variables que no sean las utilizadas en la pregunta anterior. ¿Cuál es el error de test de este árbol?

```{r}
# MODELO CON LAS VARIABLES GILL.SIZE Y CAP.SHAPE
modWorst = train(class ~ gill.size + cap.shape,
            data = train,
            method = "rpart2",
            trControl = ctrl)
```

```{r}
# GRAFICAR PRECISIONES
plot(modWorst)
```

```{r}
# ARBOL OPTIMO
modWorst$bestTune
```

Utilizando otras dos variables, el árbol óptimo, con una profundidad de tamaño 2, apenas alcanza una precisión en su proceso de validación cercana al 76%. El árbol óptimo con las variables `odor` y `ring.type`, en los 3 casos, sigue siendo el mejor modelo.

```{r}
# ARBOL FINAL
fancyRpartPlot(modWorst$finalModel)
```

```{r}
# MODELOS EN LISTA
models = list("AllVariables" = modAll,
              "Odor.Ringtype" = modBest,
              "Gillsize.Capshape" = modWorst)

# TEST DE LOS MODELOS
pred = predict(models,newdata = test)
```

```{r}
# PRECISION EN TEST PARA EL MODELO CON TODAS LAS VARIABLES
confusionMatrix(pred$AllVariables,truth)
```

La precisión del modelo óptimo utilizando todas las variables alcanza un 98.87%. En el caso de las setas, predice como comestibles un total de 11 setas que en realidad son venenosas (Predicción positiva del 98.95%), que si bien no es un número alto, es una clasificación no deseada, ya que trae un peligro asociado mayor que clasificar una seta comestible como venenosa.

```{r}
# PRECISION EN TEST PARA EL MODELO CON LAS VARIABLES ODOR Y RING.TYPE
confusionMatrix(pred$Odor.Ringtype,truth)
```

La precisión del modelo óptimo utilizando las dos mejores variables alcanza un 98.42%. En el caso de las setas, predice como comestibles un total de 32 setas que en realidad son venenosas (Predicción positiva del 97.05%), siendo mayor el caso de falsos positivos que en el modelo con todas las variables. Teniendo en cuenta que es preferible clasificar una seta como venenosa aunque sea comestible, se debe considerar utilizar el modelo que utiliza todas las variables, ya que, aunque utiliza muchas más dimensiones que este modelo con las dos mejores variables, predice en menor medida setas que en verdad son venenosas como comestibles.

```{r}
# PRECISION EN TEST PARA EL MODELO CON LAS VARIABLES GILL.SIZE Y CAP.SHAPE
confusionMatrix(pred$Gillsize.Capshape,truth)
```

La precisión del modelo óptimo utilizando dos variables cualesquiera, omitiendo las dos mejores, alcanza un 75.92%. En el caso de las setas, predice como comestibles un total de 419 setas que en realidad son venenosas (Predicción positiva del 70.09%), siendo mucho mayor el caso de falsos positivos frente a los otros dos modelos. Solamente teniendo en cuenta esta predicción, este modelo se descarta.

### Punto 3 (3 puntos):

Por un lado, las ramas del árbol pueden ser interpretadas como reglas de forma similar a las obtenidas por el algoritmo de reglas aplicado. Por ejemplo, en el caso del árbol obtenido con el dataset `Play Tennis` puede obtenerse las siguientes `reglas`: SI Outlook = Overcast -> Play Tennis = Yes ó SI (Outlook = Sunny) AND (Humidity = Normal) -> Play Tennis = Yes, cuya confianza asociada viene dada por la frecuencia relativa de cada caso en esa rama del árbol. Por otro lado, considerando las reglas que implican a nuestra variable objetivo tendríamos un `modelo` similar al dado por el árbol. Considerar y comparar ambas aproximaciones (p.e. ¿coinciden los antecedentes de las reglas? ¿alguna de las variables más frecuentes como antecedente en las reglas se corresponde con alguna de las variables con mayor capacidad de discriminación? etc.).

```{r}
# ARBOL FINAL
fancyRpartPlot(modAll$finalModel)
```

```{r}
# ARBOL FINAL
modAll$finalModel
```

```{r}
# REGLAS A DATA FRAME
ruledf = data.frame(lhs = labels(lhs(cons_rules)),
                    rhs = labels(rhs(cons_rules)),
                    cons_rules@quality)
```

```{r}
# 5 PRIMERAS REGAS ORDENADAS POR SOPORTE
head(ruledf[order(-ruledf$support),])
```

En las reglas de asociación, la variable `Odor=none` como antecedente del consecuente `Class=edible` es la regla que mayor soporte tiene de todas las reglas de asociación. En comparación con el árbol final del modelo que tiene en cuenta todas las variables, `Odor=none` es la variable con el valor asociado de mayor peso, en el casi de ser cierto, en el 97% del 43% de los casos la clase es comestible (`Class=edible`).

```{r}
# PATRON DEFINIDO PARA REGLAS DE ASOCIACION QUE EMPEICEN CON LA VARIABLE ODOR
patt = glob2rx("{Odor*")

# FILTRAR DATAFRAME POR PATRON
ruleOdor = ruledf[grep(patt,ruledf$lhs),]
ruleOdor
```

También se define claramente por las reglas de asociación que la variable `Odor=foul` como antecedente del consecuente `Class=poisonous` determina esta clasificación en el árbol final, ya que del 48% de los casos el 99% será clasificado como venenoso si no se cumple `Odor=l`. Del 9% restante de los casos, sólo una unidad porcentual tenderá a ser clasificada como venenosa, mientras el resto será clasificada como comestible.

Hay una similitud alta entre las reglas de asociación y el árbol generado, no obstante, las variables objetivo en el consecuente, así como las variables dependientes a clasificar en el árbol dependerán en la mayoría de los casos de ciertas variables específicas que tienen un mayor peso a la hora de clasificar.