{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_S1_VaDy0yj"
   },
   "source": [
    "# Almacenamiento de Agua\n",
    "\n",
    "Importar librerías a usar.\n",
    "\n",
    "- Numpy\n",
    "- ee: API de Google Earth Engine\n",
    "- folium: visualización de mapas sobre Leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVhj3SbGy0yk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ee\n",
    "import folium\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7jejSw9y0yo"
   },
   "source": [
    "Inicializar sesión de Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "Kl9e05k_y0yp",
    "outputId": "877fd87b-ae42-4bc6-c3bc-96a4d2e53d53"
   },
   "outputs": [],
   "source": [
    "#!earthengine authenticate\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTikWevOy0ys"
   },
   "source": [
    "Parámetros de visualización (composición de bandas) para Sentinel-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N1ggO9OIy0yt"
   },
   "outputs": [],
   "source": [
    "visRGB = {\"bands\": [\"B4\",\"B3\",\"B2\"],\"min\":0,\"max\":2000}\n",
    "visRGBref = {\"bands\": [\"B4\",\"B3\",\"B2\"],\"min\":0,\"max\":0.2}\n",
    "visRGB_water = {\"bands\": [\"B4\",\"B3\",\"B2\"],\"min\":0,\"max\":800}\n",
    "visIndex = {\"min\":0,\"max\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8-6mcoyckod"
   },
   "outputs": [],
   "source": [
    "bands10m = ['B2','B3','B4','B8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHdi5FZay0yx"
   },
   "source": [
    "## Datos iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzmVPBjAy0yx"
   },
   "source": [
    "### Fecha\n",
    "\n",
    "- interestDate: Fecha deseada para la cual se desea calcular el volumen de agua almacenada.\n",
    "- deltaDays: Rango de fechas para buscar imágenes adicionales +/- la fecha de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkidOPkqy0yy"
   },
   "outputs": [],
   "source": [
    "interestDate = \"2019-10-22\"\n",
    "deltaDays = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STn8tQlLy0y0"
   },
   "source": [
    "### Región\n",
    "\n",
    "- xmin: longitud mínima.\n",
    "- xmax: longitud máxima.\n",
    "- ymin: latitud mínima.\n",
    "- ymax: latitud máxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8iL1WX9y0y1"
   },
   "outputs": [],
   "source": [
    "xmin = -8.22603391725042\n",
    "ymin = 41.85962828770244\n",
    "xmax = -8.063298931898858\n",
    "ymax = 41.93092895284894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIqoPBhny0y4"
   },
   "outputs": [],
   "source": [
    "centerx = np.array([xmin,xmax]).mean()\n",
    "centery = np.array([ymin,ymax]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuPyKhVuy0y7"
   },
   "outputs": [],
   "source": [
    "ROI = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzr_kkVAy0y-"
   },
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YrEhn45Ky0y-"
   },
   "source": [
    "### 1. Visualización de una imagen en Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oz8KzZwZy0y_"
   },
   "outputs": [],
   "source": [
    "def foliumLayer(image,parameters = visRGB,layer_name = \"layer\"):\n",
    "    \n",
    "    folium_map = folium.Map(location = [centery,centerx],zoom_start = 13,tiles = 'openstreetmap')\n",
    "    \n",
    "    mapIdDict = image.getMapId(parameters) # convertir imagen a id de visualizacion\n",
    "    \n",
    "    tile = folium.TileLayer(tiles = mapIdDict['tile_fetcher'].url_format,\n",
    "                            attr = 'Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "                            overlay = True,\n",
    "                            name = layer_name)\n",
    "    \n",
    "    tile.add_to(folium_map)\n",
    "    \n",
    "    folium_map.add_child(folium.LayerControl())\n",
    "    \n",
    "    return folium_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6aCtYiny0zB"
   },
   "source": [
    "### 2. Cortar imágenes por ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzqEogeCy0zB"
   },
   "outputs": [],
   "source": [
    "def clip_images(image):\n",
    "        \n",
    "    return image.clip(ROI).copyProperties(image,[\"system:time_start\"]) # retornar imagenes recortadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0S5DvzoSy0zF"
   },
   "source": [
    "### 3. Enmascarar nubes y sombras de una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSDe5yWay0zG"
   },
   "outputs": [],
   "source": [
    "def clouds_shadows_mask(image):\n",
    "    \n",
    "    shadows_mask = image.select('SCL').eq(3).Not() # pixeles que no son sombra\n",
    "    clouds_mask = image.select('SCL').lt(7).Or(image.select('SCL').gt(9)) # pixeles que no son nubes\n",
    "    empirical_clouds_mask = image.select('B2').lte(1500) # Pixeles que no son nubes\n",
    "    clouds_mask = clouds_mask.And(empirical_clouds_mask) # Pixeles que no son nubes\n",
    "    mask = shadows_mask.And(clouds_mask) # pixeles que no son ni sombra ni nubes\n",
    "    \n",
    "    return image.updateMask(mask).copyProperties(image,[\"system:time_start\"]) # retornar imagenes enmascaradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWkVWo2gy0zJ"
   },
   "source": [
    "### 4. Seleccionar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cOVakTOy0zK"
   },
   "outputs": [],
   "source": [
    "def collectS2Images(interestDate,deltaDays,ROI,clipImages = True):\n",
    "        \n",
    "    interestDate = np.datetime64(interestDate)\n",
    "    initialDate = np.datetime_as_string(interestDate - np.timedelta64(deltaDays,'D'))\n",
    "    finalDate = np.datetime_as_string(interestDate + np.timedelta64(deltaDays,'D'))\n",
    "    \n",
    "    IC = ee.ImageCollection(\"COPERNICUS/S2_SR\").filterDate(initialDate,finalDate).filterBounds(ROI)\n",
    "    \n",
    "    if clipImages:\n",
    "        \n",
    "        def clip_images(image):        \n",
    "            return image.clip(ROI).copyProperties(image,[\"system:time_start\"]) # retornar imagenes recortadas\n",
    "        \n",
    "        IC = IC.map(clip_images)\n",
    "    \n",
    "    return IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4SWOLyocy0zO"
   },
   "source": [
    "### 5. Calcular Reflectancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nBxYggRy0zO"
   },
   "outputs": [],
   "source": [
    "def reflectance(image):\n",
    "        \n",
    "    return ee.Image(image.multiply(0.0001).copyProperties(image,[\"system:time_start\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntZqqNPvy0zQ"
   },
   "source": [
    "### 6. Máscara de agua automática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8Os9CBXy0zR"
   },
   "outputs": [],
   "source": [
    "def automaticWaterMask(image,ROI,index = \"GNDVI\",seedSpacing = 20,gridType = \"square\",compactness = 1,connectivity = 8,scale = 10,k = 3,pTrain = 0.8):\n",
    "\n",
    "    print(\"Determinando de máscara de agua...\")\n",
    "    \n",
    "    print(\"******************************\")    \n",
    "    if index == \"GNDVI\":\n",
    "        idx = image.normalizedDifference(['B8','B3'])\n",
    "    elif index == \"NDWI\":\n",
    "        idx = image.normalizedDifference(['B3','B8'])\n",
    "    \n",
    "    seeds = ee.Algorithms.Image.Segmentation.seedGrid(seedSpacing,gridType)    \n",
    "    SNIC = ee.Algorithms.Image.Segmentation.SNIC(image = ee.Image.cat([image.select(['B2','B3','B4','B8']),idx]),                                             \n",
    "                                                 compactness = compactness,\n",
    "                                                 connectivity = 8,                                                 \n",
    "                                                 seeds = seeds)\n",
    "    SNIC = SNIC.select(['B2_mean','B3_mean','B4_mean','B8_mean','nd_mean','clusters'], ['B2','B3','B4','B8','idx','clusters'])\n",
    "    \n",
    "    nseeds = seeds.reduceRegion(reducer = ee.Reducer.count(),geometry = ROI,scale = scale).getInfo()['seeds']\n",
    "    ntrain = round(nseeds*pTrain)\n",
    "    if ntrain > 10000:\n",
    "        ntrain = 10000\n",
    "    #elif ntrain < 1000:\n",
    "    #    ntrain = 1000\n",
    "    #ntrain = 5000\n",
    "    objectPropertiesImage = SNIC.select(['B2','B3','B4','B8','idx'])\n",
    "    X_train = objectPropertiesImage.sample(scale = scale,numPixels = ntrain,region = ROI,geometries = True)\n",
    "    kmeans = ee.Clusterer.wekaKMeans(k)\n",
    "    kmeans = kmeans.train(X_train)\n",
    "    clusterImage = objectPropertiesImage.cluster(kmeans)\n",
    "    \n",
    "    values = []\n",
    "    for i in range(k):\n",
    "        cluster_mask = clusterImage.eq(i)\n",
    "        idx_clusterMasked = idx.updateMask(cluster_mask)\n",
    "        mean_value = idx_clusterMasked.reduceRegion(reducer = ee.Reducer.mean(),geometry = ROI,scale = 10)\n",
    "        values.append(mean_value.getInfo()['nd'])\n",
    "        print(\"---> Avance:\",round((i+1)*100/(k),2),\"% <---\")\n",
    "        \n",
    "    if index == \"GNDVI\":\n",
    "        cluster_water = np.array(values).argmin().item()\n",
    "    elif index == \"NDWI\":\n",
    "        cluster_water = np.array(values).argmax().item()    \n",
    "\n",
    "    print(\"Proceso finalizado\")\n",
    "    water_mask = clusterImage.eq(cluster_water)\n",
    "    \n",
    "    return water_mask, idx, SNIC, X_train, clusterImage, ntrain, nseeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDTyOxZLy0zT"
   },
   "source": [
    "### 7. Crear Costo Acumulado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKGoy9kny0zU"
   },
   "outputs": [],
   "source": [
    "def depthCumulativeCost(waterMask,ROI,scale = 10,maxDistance = 1000):\n",
    "\n",
    "    water_poly = waterMask.reduceToVectors(geometry = ROI,scale = scale,eightConnected = False)\n",
    "    water_poly = water_poly.filter(ee.Filter.eq('label',1))\n",
    "\n",
    "    coords = water_poly.geometry().coordinates().getInfo()\n",
    "    lines = []\n",
    "    for i in range(len(coords)):\n",
    "        for j in range(len(coords[i])):\n",
    "            lines.append(ee.Geometry.LineString(coords[i][j]))\n",
    "\n",
    "    allLines = ee.FeatureCollection(lines)\n",
    "\n",
    "    sources = ee.Image().toByte().paint(allLines, 1)\n",
    "    sources = sources.updateMask(sources)\n",
    "\n",
    "    cumulativeCost = waterMask.cumulativeCost(source = sources,maxDistance = maxDistance).updateMask(waterMask)\n",
    "    \n",
    "    return cumulativeCost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APwebBO0y0zW"
   },
   "source": [
    "### 8. Leer Batimetría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnoCtLOpy0zX"
   },
   "outputs": [],
   "source": [
    "def loadBathymetry(filePath,delimeter = \"/t\",usecols = (2,3,5),startLine = 7):\n",
    "\n",
    "    f = open(filePath)\n",
    "    textList = f.readlines()[startLine:]\n",
    "\n",
    "    outF = open(\"bathyTemp.txt\",\"w\")\n",
    "    for line in textList:\n",
    "        line = line.replace(\",\",\".\")\n",
    "        outF.write(line)    \n",
    "    outF.close()\n",
    "\n",
    "    bathy = np.loadtxt(\"bathyTemp.txt\",delimiter = delimeter,usecols = usecols)\n",
    "    \n",
    "    return bathy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "01GoArbLy0za"
   },
   "source": [
    "### 9. Extraer datos de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVL2bo1xy0za"
   },
   "outputs": [],
   "source": [
    "def pixelDataFromCoordinates(image,coords,coordsCols = [0,1],batchSize = 5000,scale = 10,joinData = True,toPandas = True):\n",
    "    \n",
    "    extractedData = []\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    print(\"Comenzando la extracción de datos...\")\n",
    "    while k <= coords.shape[0]:\n",
    "\n",
    "        print(\"******************************\")\n",
    "        print(\"Creando nuevo batch...\")\n",
    "        pointFeatures = []\n",
    "\n",
    "        initial = k\n",
    "        print(\"Inicia en\",initial)\n",
    "\n",
    "        if k + batchSize > coords.shape[0]:\n",
    "            final = coords.shape[0]\n",
    "        else:\n",
    "            final = k + batchSize\n",
    "        print(\"Finaliza en\",final)\n",
    "\n",
    "        print(\"Realizando extracción...\")\n",
    "        for i in range(initial,final):\n",
    "            pointFeatures.append(ee.Geometry.Point([coords[i,coordsCols[0]],coords[i,coordsCols[1]]]))\n",
    "\n",
    "        fromList = ee.FeatureCollection(pointFeatures)\n",
    "\n",
    "        imageDictionary = image.reduceRegions(collection = fromList,reducer = ee.Reducer.first(),scale = scale)\n",
    "\n",
    "        features = imageDictionary.getInfo()['features']\n",
    "\n",
    "        for i in range(len(features)):\n",
    "            extractedData.append(list(features[i]['properties'].values()))\n",
    "\n",
    "        print(\"Extracción finalizada\")\n",
    "        print(\"---> Avance:\",round(final*100/coords.shape[0],1),\"% <---\")\n",
    "\n",
    "        k = k + batchSize\n",
    "    \n",
    "    if joinData:\n",
    "        extractedData = np.concatenate((coords,np.array(extractedData)),axis = 1)\n",
    "    \n",
    "    if toPandas:\n",
    "        extractedData = pd.DataFrame(extractedData)\n",
    "    \n",
    "    return extractedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BvJFB0J5y0zd"
   },
   "source": [
    "### 10. Máscara de Gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Mq9HqGNy0ze"
   },
   "outputs": [],
   "source": [
    "def clouds_shadows_mask_gaps(image):\n",
    "    \n",
    "    shadows_mask = image.select('SCL').eq(3).Not() # pixeles que no son sombra\n",
    "    clouds_mask = image.select('SCL').lt(7).Or(image.select('SCL').gt(9)) # pixeles que no son nubes\n",
    "    empirical_clouds_mask = image.select('B2').lte(1500) # Pixeles que no son nubes\n",
    "    clouds_mask = clouds_mask.And(empirical_clouds_mask) # Pixeles que no son nubes\n",
    "    mask = shadows_mask.And(clouds_mask) # pixeles que no son ni sombra ni nubes\n",
    "    \n",
    "    return mask.Not() # retornar todo lo que sea nube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3lNkjznty0zg"
   },
   "source": [
    "### 11. Fill Gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pho2t7bUy0zg"
   },
   "outputs": [],
   "source": [
    "def fillGaps(imageCollection,imageReduced):\n",
    "\n",
    "    gaps_mask = imageCollection.map(clouds_shadows_mask_gaps).product().toByte()\n",
    "\n",
    "    kernelList = [[1,1,1],[1,0,1],[1,1,1]]\n",
    "    kernel = ee.Kernel.fixed(3,3,kernelList,-1,-1,False)\n",
    "\n",
    "    imageUnmasked = imageReduced.unmask()\n",
    "\n",
    "    imageConvolved = imageReduced.focal_median(kernel = kernel,iterations = 50)\n",
    "\n",
    "    imageFilled = imageConvolved.multiply(gaps_mask).add(imageUnmasked)\n",
    "    \n",
    "    return imageFilled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Matriz de Confusión entre dos imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageConfusionMatrix(truthImage,predictedImage,ROI,scale = 10):\n",
    "    \n",
    "    print(\"Generando Matriz de Confusión...\")\n",
    "    print(\"******************************\")\n",
    "    predictedImage = predictedImage.multiply(10)\n",
    "    confusion_image = truthImage.add(predictedImage)\n",
    "\n",
    "    TN = confusion_image.eq(0)\n",
    "    TN = TN.updateMask(TN).reduceRegion(ee.Reducer.count(),ROI,scale = scale).getInfo()['nd']\n",
    "    print(\"---> Avance: 25 % <---\")\n",
    "\n",
    "    FN = confusion_image.eq(1)\n",
    "    FN = FN.updateMask(FN).reduceRegion(ee.Reducer.count(),ROI,scale = scale).getInfo()['nd']\n",
    "    print(\"---> Avance: 50 % <---\")\n",
    "\n",
    "    FP = confusion_image.eq(10)\n",
    "    FP = FP.updateMask(FP).reduceRegion(ee.Reducer.count(),ROI,scale = scale).getInfo()['nd']\n",
    "    print(\"---> Avance: 75 % <---\")\n",
    "\n",
    "    TP = confusion_image.eq(11)\n",
    "    TP = TP.updateMask(TP).reduceRegion(ee.Reducer.count(),ROI,scale = scale).getInfo()['nd']\n",
    "    print(\"---> Avance: 100 % <---\")\n",
    "    \n",
    "    print(\"Proceso finalizado\")\n",
    "    \n",
    "    return [TP,FP,TN,FN], confusion_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingPipeline(images,ROI,masking = True,gapFilling = True,calculateReflectance = True,smoothing = True):    \n",
    "    \n",
    "    print(\"Iniciando preprocesamiento...\")\n",
    "    original = images\n",
    "    \n",
    "    if type(images) == ee.imagecollection.ImageCollection:        \n",
    "        if masking:\n",
    "            print(\"Enmascarando nubes y sombras\")\n",
    "            images = images.map(clouds_shadows_mask)\n",
    "        images = images.median().select(['B2','B3','B4','B8']).clip(ROI)\n",
    "        if gapFilling:\n",
    "            print(\"Rellenando vacíos\")\n",
    "            images = fillGaps(original,images)\n",
    "        if calculateReflectance:\n",
    "            print(\"Calculando reflectancia\")\n",
    "            images = reflectance(images)\n",
    "        if smoothing:\n",
    "            print(\"Filtrando imagen\")\n",
    "            images = images.focal_median(radius = 1,kernelType = \"square\")\n",
    "    \n",
    "    elif type(images) == ee.image.Image:        \n",
    "        if masking:\n",
    "            print(\"Enmascarando nubes y sombras\")\n",
    "            images = clouds_shadows_mask(images)\n",
    "        images = images.select(['B2','B3','B4','B8']).clip(ROI)\n",
    "        if gapFilling:\n",
    "            print(\"Rellenando vacíos\")\n",
    "            images = fillGaps(original,images)\n",
    "        if calculateReflectance:\n",
    "            print(\"Calculando reflectancia\")\n",
    "            images = reflectance(images)\n",
    "        if smoothing:\n",
    "            print(\"Filtrando imagen\")\n",
    "            images = images.focal_median(radius = 1,kernelType = \"square\")\n",
    "    \n",
    "    return images        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgqyHKGoy0zj"
   },
   "source": [
    "# ALTO LINDOSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensión del embalse y generación del área de interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = -8.2260339\n",
    "ymin = 41.8596283\n",
    "xmax = -8.0632989\n",
    "ymax = 41.9309290\n",
    "\n",
    "centerx = np.array([xmin,xmax]).mean()\n",
    "centery = np.array([ymin,ymax]).mean()\n",
    "\n",
    "ROI = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imágenes a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alto_lindoso = ee.Image(\"COPERNICUS/S2_SR/20191022T112121_20191022T112445_T29TNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alto_lindoso = preprocessingPipeline(alto_lindoso,ROI,masking = False,gapFilling = False)\n",
    "foliumLayer(alto_lindoso,visRGBref,\"Preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDWI_alto_lindoso = alto_lindoso.normalizedDifference(['B3','B8'])\n",
    "truthMask_alto_lindoso = NDWI_alto_lindoso.gt(-0.15)\n",
    "foliumLayer(truthMask_alto_lindoso,{},\"WM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.batch.Export.image.toAsset(image = alto_lindoso,description = \"Preprocessed_AL\",assetId = \"users/dmlmont/TFM/Pre_Alto_Lindoso\",scale = 10,region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(alto_lindoso,\n",
    "                                                                          ROI,\n",
    "                                                                          index = \"NDWI\",\n",
    "                                                                          seedSpacing = 10,\n",
    "                                                                          gridType = \"square\",\n",
    "                                                                          k = 4,\n",
    "                                                                          pTrain = 2)\n",
    "\n",
    "ee.batch.Export.image.toAsset(image = wm,description = \"WMp\",assetId = \"users/dmlmont/TFM/WMp_Alto_Lindoso\",scale = 10,region = ROI).start()\n",
    "ee.batch.Export.image.toAsset(image = truthMask_alto_lindoso,description = \"WMt\",assetId = \"users/dmlmont/TFM/WMt_Alto_Lindoso\",scale = 10,region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(alto_lindoso,\n",
    "                                                                          ROI,\n",
    "                                                                          index = \"NDWI\",\n",
    "                                                                          seedSpacing = 10,\n",
    "                                                                          gridType = \"square\",\n",
    "                                                                          k = 4,\n",
    "                                                                          pTrain = 2)\n",
    "\n",
    "cm, cm_image = imageConfusionMatrix(truthMask_alto_lindoso,wm,ROI)\n",
    "\n",
    "toExport = [alto_lindoso,wm,idx,SNIC,clusterImage,truthMask_alto_lindoso,cm_image]\n",
    "prefix = [\"Preprocessed\",\"WMp\",\"Idx\",\"SNIC\",\"Clusters\",\"WMt\",\"CM\"]\n",
    "suffix = \"Alto_Lindoso\"\n",
    "toFilenames = []\n",
    "\n",
    "for p in prefix:\n",
    "    toFilenames.append(p + '_' + suffix)\n",
    "    \n",
    "i = 3\n",
    "ee.batch.Export.image.toDrive(image = toExport[i].toFloat(),\n",
    "                                  description = toFilenames[i],\n",
    "                                  folder = \"GEE\",\n",
    "                                  scale = 10,\n",
    "                                  region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toExport = [alto_lindoso,wm,idx,SNIC,clusterImage,truthMask_alto_lindoso,cm_image]\n",
    "prefix = [\"Preprocessed\",\"WMp\",\"Idx\",\"SNIC\",\"Clusters\",\"WMt\",\"CM\"]\n",
    "suffix = \"Alto_Lindoso\"\n",
    "toFilenames = []\n",
    "\n",
    "for p in prefix:\n",
    "    toFilenames.append(p + '_' + suffix)\n",
    "    \n",
    "for i in range(len(toExport)):\n",
    "    ee.batch.Export.image.toDrive(image = toExport[i],\n",
    "                                  description = toFilenames[i],\n",
    "                                  folder = \"GEE\",\n",
    "                                  scale = 10,\n",
    "                                  region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(toExport)):\n",
    "    ee.batch.Export.image.toDrive(image = toExport[i],\n",
    "                                  description = toFilenames[i],\n",
    "                                  folder = \"GEE\",\n",
    "                                  scale = 10,\n",
    "                                  region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "cm_df = pd.DataFrame(np.array(cm))\n",
    "gt_df = pd.DataFrame(np.array(gt))\n",
    "ss_df = pd.DataFrame(np.array(ss))\n",
    "ks_df = pd.DataFrame(np.array(ks))\n",
    "tm_df = pd.DataFrame(np.array(tm))\n",
    "nt_df = pd.DataFrame(np.array(nt))\n",
    "ns_df = pd.DataFrame(np.array(ns))\n",
    "pt_df = pd.DataFrame(np.array(pt))\n",
    "\n",
    "df = pd.concat([gt_df,ss_df,ks_df,nt_df,ns_df,tm_df,pt_df,cm_df],axis = 1)\n",
    "df.columns = ['GridType','SeedSpacing','k','nTrain','Superpixels','Time','TrainingPrSuperpixels','TP','FP','TN','FN']\n",
    "\n",
    "df['TotalPixels'] = df['TP'] + df['FP'] + df['FN'] + df['TN']\n",
    "df['SuperpixelsProportion'] = df['Superpixels']/df['TotalPixels']\n",
    "df['TrainingPrPixels'] = df['nTrain']/df['TotalPixels']\n",
    "\n",
    "df['FPR'] = df['FP']/(df['FP'] + df['TN'])\n",
    "df['FNR'] = df['FN']/(df['FN'] + df['TP'])\n",
    "df['Sensitivity'] = 1 - df['FNR']\n",
    "df['Specificity'] = 1 - df['FPR']\n",
    "\n",
    "df['FDR'] = df['FP']/(df['FP'] + df['TP'])\n",
    "df['FOR'] = df['FN']/(df['FN'] + df['TN'])\n",
    "df['Precision'] = 1 - df['FDR']\n",
    "df['NPV'] = 1 - df['FOR']\n",
    "\n",
    "df['Accuracy'] = (df['TP'] + df['TN'])/(df['TP'] + df['TN'] + df['FP'] + df['FN'])\n",
    "#df['MCC'] = ((df['TP'] * df['TN']) - (df['FP'] * df['FN']))/np.sqrt((df['TP'] + df['FP'])*(df['TP'] + df['FN'])*(df['TN'] + df['FP'])*(df['TN'] + df['FN']))\n",
    "#df['F1'] = 2*(df['Precision']*df['Sensitivity'])/(df['Precision'] + df['Sensitivity'])\n",
    "\n",
    "df.to_csv(\"C:/Users/Dave Mont/Desktop/Master_of_DataScience/TFM/Results/water_mask/cm_alto_lindoso_n.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "gt = []\n",
    "ss = []\n",
    "ks = []\n",
    "cm = []\n",
    "tm = []\n",
    "nt = []\n",
    "ns = []\n",
    "pt = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for pTrain in [0.5,0.75,0.8,0.9,1,1.5,2]:\n",
    "    for gridType in [\"square\",\"hex\"]:\n",
    "        for seedSpacing in [10,20,30,40]:                    \n",
    "            for k in [3,4,5]:\n",
    "\n",
    "                print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "                print(\"-------> EMPIEZA NUMERO:\",i)\n",
    "                print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "                gt.append(gridType)\n",
    "                ss.append(seedSpacing)            \n",
    "                ks.append(k)\n",
    "                pt.append(pTrain)\n",
    "\n",
    "                start = time.time()\n",
    "                wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(alto_lindoso,\n",
    "                                                                                          ROI,\n",
    "                                                                                          index = \"NDWI\",\n",
    "                                                                                          seedSpacing = seedSpacing,\n",
    "                                                                                          gridType = gridType,\n",
    "                                                                                          k = k,\n",
    "                                                                                          pTrain = pTrain)\n",
    "                end = time.time()\n",
    "                print(end - start,\"s\")\n",
    "                tm.append(end - start)\n",
    "                nt.append(ntrain)\n",
    "                ns.append(nseeds)\n",
    "\n",
    "                cm.append(imageConfusionMatrix(truthMask_alto_lindoso,wm,ROI))\n",
    "\n",
    "                i = i + 1\n",
    "            \n",
    "cm_df = pd.DataFrame(np.array(cm))\n",
    "gt_df = pd.DataFrame(np.array(gt))\n",
    "ss_df = pd.DataFrame(np.array(ss))\n",
    "ks_df = pd.DataFrame(np.array(ks))\n",
    "tm_df = pd.DataFrame(np.array(tm))\n",
    "nt_df = pd.DataFrame(np.array(nt))\n",
    "ns_df = pd.DataFrame(np.array(ns))\n",
    "pt_df = pd.DataFrame(np.array(pt))\n",
    "\n",
    "df = pd.concat([gt_df,ss_df,ks_df,nt_df,ns_df,tm_df,pt_df,cm_df],axis = 1)\n",
    "df.columns = ['GridType','SeedSpacing','k','nTrain','Superpixels','Time','TrainingPrSuperpixels','TP','FP','TN','FN']\n",
    "\n",
    "df['TotalPixels'] = df['TP'] + df['FP'] + df['FN'] + df['TN']\n",
    "df['SuperpixelsProportion'] = df['Superpixels']/df['TotalPixels']\n",
    "df['TrainingPrPixels'] = df['nTrain']/df['TotalPixels']\n",
    "\n",
    "df['FPR'] = df['FP']/(df['FP'] + df['TN'])\n",
    "df['FNR'] = df['FN']/(df['FN'] + df['TP'])\n",
    "df['Sensitivity'] = 1 - df['FNR']\n",
    "df['Specificity'] = 1 - df['FPR']\n",
    "\n",
    "df['FDR'] = df['FP']/(df['FP'] + df['TP'])\n",
    "df['FOR'] = df['FN']/(df['FN'] + df['TN'])\n",
    "df['Precision'] = 1 - df['FDR']\n",
    "df['NPV'] = 1 - df['FOR']\n",
    "\n",
    "df['Accuracy'] = (df['TP'] + df['TN'])/(df['TP'] + df['TN'] + df['FP'] + df['FN'])\n",
    "#df['MCC'] = ((df['TP'] * df['TN']) - (df['FP'] * df['FN']))/np.sqrt((df['TP'] + df['FP'])*(df['TP'] + df['FN'])*(df['TN'] + df['FP'])*(df['TN'] + df['FN']))\n",
    "#df['F1'] = 2*(df['Precision']*df['Sensitivity'])/(df['Precision'] + df['Sensitivity'])\n",
    "\n",
    "df.to_csv(\"C:/Users/Dave Mont/Desktop/Master_of_DataScience/TFM/Results/water_mask/cm_alto_lindoso_n.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = ['Accuracy'],ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = -0.3245736\n",
    "ymin = 42.6798840\n",
    "xmax = -0.2969361\n",
    "ymax = 42.7209728\n",
    "\n",
    "centerx = np.array([xmin,xmax]).mean()\n",
    "centery = np.array([ymin,ymax]).mean()\n",
    "\n",
    "ROI = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubal = ee.Image(\"COPERNICUS/S2_SR/20170824T105031_20170824T105240_T30TYN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubal = preprocessingPipeline(bubal,ROI,masking = False,gapFilling = False)\n",
    "foliumLayer(bubal,visRGBref,\"Preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDWI_bubal = bubal.normalizedDifference(['B3','B8'])\n",
    "truthMask_bubal = NDWI_bubal.gt(0.66)\n",
    "foliumLayer(truthMask_bubal,{},\"WM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.batch.Export.image.toAsset(image = bubal,description = \"Preprocessed_B\",assetId = \"users/dmlmont/TFM/Pre_Bubal\",scale = 10,region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(bubal,\n",
    "                                                                          ROI,\n",
    "                                                                          index = \"NDWI\",\n",
    "                                                                          seedSpacing = 10,\n",
    "                                                                          gridType = \"square\",\n",
    "                                                                          k = 4,\n",
    "                                                                          pTrain = 2)\n",
    "\n",
    "ee.batch.Export.image.toAsset(image = wm,description = \"WMp\",assetId = \"users/dmlmont/TFM/WMp_Bubal\",scale = 10,region = ROI).start()\n",
    "ee.batch.Export.image.toAsset(image = truthMask_bubal,description = \"WMt\",assetId = \"users/dmlmont/TFM/WMt_Bubal\",scale = 10,region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.data.getTaskList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Task.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(bubal,\n",
    "                                                                          ROI,\n",
    "                                                                          index = \"NDWI\",\n",
    "                                                                          seedSpacing = 10,\n",
    "                                                                          gridType = \"square\",\n",
    "                                                                          k = 4,\n",
    "                                                                          pTrain = 2)\n",
    "\n",
    "cm, cm_image = imageConfusionMatrix(truthMask_bubal,wm,ROI)\n",
    "\n",
    "toExport = [bubal,wm,idx,SNIC,clusterImage,truthMask_bubal,cm_image]\n",
    "prefix = [\"Preprocessed\",\"WMp\",\"Idx\",\"SNIC\",\"Clusters\",\"WMt\",\"CM\"]\n",
    "suffix = \"Bubal\"\n",
    "toFilenames = []\n",
    "\n",
    "for p in prefix:\n",
    "    toFilenames.append(p + '_' + suffix)\n",
    "    \n",
    "for i in range(len(toExport)):\n",
    "    ee.batch.Export.image.toDrive(image = toExport[i],\n",
    "                                  description = toFilenames[i],\n",
    "                                  folder = \"GEE\",\n",
    "                                  scale = 10,\n",
    "                                  region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "ee.batch.Export.image.toDrive(image = toExport[i].toFloat(),\n",
    "                                  description = toFilenames[i],\n",
    "                                  folder = \"GEE\",\n",
    "                                  scale = 10,\n",
    "                                  region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "gt = []\n",
    "ss = []\n",
    "ks = []\n",
    "cm = []\n",
    "tm = []\n",
    "nt = []\n",
    "ns = []\n",
    "pt = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for pTrain in [0.5,0.75,0.8,0.9,1,1.5,2]:\n",
    "    for gridType in [\"square\",\"hex\"]:\n",
    "        for seedSpacing in [10,20,30,40]:                    \n",
    "            for k in [3,4,5]:\n",
    "\n",
    "                print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "                print(\"-------> EMPIEZA NUMERO:\",i)\n",
    "                print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "                gt.append(gridType)\n",
    "                ss.append(seedSpacing)            \n",
    "                ks.append(k)\n",
    "                pt.append(pTrain)\n",
    "\n",
    "                start = time.time()\n",
    "                wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(bubal,\n",
    "                                                                                          ROI,\n",
    "                                                                                          index = \"NDWI\",\n",
    "                                                                                          seedSpacing = seedSpacing,\n",
    "                                                                                          gridType = gridType,\n",
    "                                                                                          k = k,\n",
    "                                                                                          pTrain = pTrain)\n",
    "                end = time.time()\n",
    "                print(end - start,\"s\")\n",
    "                tm.append(end - start)\n",
    "                nt.append(ntrain)\n",
    "                ns.append(nseeds)\n",
    "\n",
    "                cm.append(imageConfusionMatrix(truthMask_bubal,wm,ROI))\n",
    "\n",
    "                i = i + 1\n",
    "            \n",
    "cm_df = pd.DataFrame(np.array(cm))\n",
    "gt_df = pd.DataFrame(np.array(gt))\n",
    "ss_df = pd.DataFrame(np.array(ss))\n",
    "ks_df = pd.DataFrame(np.array(ks))\n",
    "tm_df = pd.DataFrame(np.array(tm))\n",
    "nt_df = pd.DataFrame(np.array(nt))\n",
    "ns_df = pd.DataFrame(np.array(ns))\n",
    "pt_df = pd.DataFrame(np.array(pt))\n",
    "\n",
    "df = pd.concat([gt_df,ss_df,ks_df,nt_df,ns_df,tm_df,pt_df,cm_df],axis = 1)\n",
    "df.columns = ['GridType','SeedSpacing','k','nTrain','Superpixels','Time','TrainingPrSuperpixels','TP','FP','TN','FN']\n",
    "\n",
    "df['TotalPixels'] = df['TP'] + df['FP'] + df['FN'] + df['TN']\n",
    "df['SuperpixelsProportion'] = df['Superpixels']/df['TotalPixels']\n",
    "df['TrainingPrPixels'] = df['nTrain']/df['TotalPixels']\n",
    "\n",
    "df['FPR'] = df['FP']/(df['FP'] + df['TN'])\n",
    "df['FNR'] = df['FN']/(df['FN'] + df['TP'])\n",
    "df['Sensitivity'] = 1 - df['FNR']\n",
    "df['Specificity'] = 1 - df['FPR']\n",
    "\n",
    "df['FDR'] = df['FP']/(df['FP'] + df['TP'])\n",
    "df['FOR'] = df['FN']/(df['FN'] + df['TN'])\n",
    "df['Precision'] = 1 - df['FDR']\n",
    "df['NPV'] = 1 - df['FOR']\n",
    "\n",
    "df['Accuracy'] = (df['TP'] + df['TN'])/(df['TP'] + df['TN'] + df['FP'] + df['FN'])\n",
    "#df['MCC'] = ((df['TP'] * df['TN']) - (df['FP'] * df['FN']))/np.sqrt((df['TP'] + df['FP'])*(df['TP'] + df['FN'])*(df['TN'] + df['FP'])*(df['TN'] + df['FN']))\n",
    "#df['F1'] = 2*(df['Precision']*df['Sensitivity'])/(df['Precision'] + df['Sensitivity'])\n",
    "\n",
    "df.to_csv(\"C:/Users/Dave Mont/Desktop/Master_of_DataScience/TFM/Results/water_mask/cm_bubal_n.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = ['Accuracy'],ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CANELLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0.5664387\n",
    "ymin = 41.9718079\n",
    "xmax = 0.7096043\n",
    "ymax = 42.1213370\n",
    "\n",
    "centerx = np.array([xmin,xmax]).mean()\n",
    "centery = np.array([ymin,ymax]).mean()\n",
    "\n",
    "ROI = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canelles1 = ee.Image(\"COPERNICUS/S2_SR/20181102T105209_20181102T105345_T30TYM\")\n",
    "canelles2 = ee.Image(\"COPERNICUS/S2_SR/20181102T105209_20181102T105345_T31TBG\")\n",
    "canelles3 = ee.Image(\"COPERNICUS/S2_SR/20181102T105209_20181102T105345_T31TCG\")\n",
    "canelles = ee.ImageCollection([canelles1,canelles2,canelles3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canelles = preprocessingPipeline(canelles,ROI,gapFilling = False)\n",
    "foliumLayer(canelles,visRGBref,\"Preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDWI_canelles = canelles.normalizedDifference(['B3','B8'])\n",
    "truthMask_canelles = NDWI_canelles.gt(-0.15)\n",
    "foliumLayer(truthMask_canelles,{},\"WM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.batch.Export.image.toAsset(image = canelles,description = \"Preprocessed_C\",assetId = \"users/dmlmont/TFM/Pre_Canelles\",scale = 10,region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(canelles,\n",
    "                                                                          ROI,\n",
    "                                                                          index = \"NDWI\",\n",
    "                                                                          seedSpacing = 10,\n",
    "                                                                          gridType = \"square\",\n",
    "                                                                          k = 4,\n",
    "                                                                          pTrain = 2)\n",
    "\n",
    "ee.batch.Export.image.toAsset(image = wm,description = \"WMp\",assetId = \"users/dmlmont/TFM/WMp_Canelles\",scale = 10,region = ROI).start()\n",
    "ee.batch.Export.image.toAsset(image = truthMask_canelles,description = \"WMt\",assetId = \"users/dmlmont/TFM/WMt_Canelles\",scale = 10,region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(canelles,\n",
    "                                                                          ROI,\n",
    "                                                                          index = \"NDWI\",\n",
    "                                                                          seedSpacing = 10,\n",
    "                                                                          gridType = \"square\",\n",
    "                                                                          k = 4,\n",
    "                                                                          pTrain = 2)\n",
    "\n",
    "cm, cm_image = imageConfusionMatrix(truthMask_canelles,wm,ROI)\n",
    "\n",
    "toExport = [canelles,wm,idx,SNIC,clusterImage,truthMask_canelles,cm_image]\n",
    "prefix = [\"Preprocessed\",\"WMp\",\"Idx\",\"SNIC\",\"Clusters\",\"WMt\",\"CM\"]\n",
    "suffix = \"Canelles\"\n",
    "toFilenames = []\n",
    "\n",
    "for p in prefix:\n",
    "    toFilenames.append(p + '_' + suffix)\n",
    "    \n",
    "for i in range(len(toExport)):\n",
    "    if i == 3:\n",
    "        ee.batch.Export.image.toDrive(image = toExport[i].toFloat(),\n",
    "                                      description = toFilenames[i],\n",
    "                                      folder = \"GEE\",\n",
    "                                      scale = 10,\n",
    "                                      region = ROI).start()\n",
    "    else:\n",
    "        ee.batch.Export.image.toDrive(image = toExport[i],\n",
    "                                      description = toFilenames[i],\n",
    "                                      folder = \"GEE\",\n",
    "                                      scale = 10,\n",
    "                                      region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "gt = []\n",
    "ss = []\n",
    "ks = []\n",
    "cm = []\n",
    "tm = []\n",
    "nt = []\n",
    "ns = []\n",
    "pt = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for pTrain in [0.5,0.75,0.8,0.9,1,1.5,2]:\n",
    "    for gridType in [\"square\",\"hex\"]:\n",
    "        for seedSpacing in [10,20,30,40]:                    \n",
    "            for k in [3,4,5]:\n",
    "\n",
    "                print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "                print(\"-------> EMPIEZA NUMERO:\",i)\n",
    "                print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "                gt.append(gridType)\n",
    "                ss.append(seedSpacing)            \n",
    "                ks.append(k)\n",
    "                pt.append(pTrain)\n",
    "\n",
    "                start = time.time()\n",
    "                wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(canelles,\n",
    "                                                                                          ROI,\n",
    "                                                                                          index = \"NDWI\",\n",
    "                                                                                          seedSpacing = seedSpacing,\n",
    "                                                                                          gridType = gridType,\n",
    "                                                                                          k = k,\n",
    "                                                                                          pTrain = pTrain)\n",
    "                end = time.time()\n",
    "                print(end - start,\"s\")\n",
    "                tm.append(end - start)\n",
    "                nt.append(ntrain)\n",
    "                ns.append(nseeds)\n",
    "\n",
    "                cm.append(imageConfusionMatrix(truthMask_canelles,wm,ROI))\n",
    "\n",
    "                i = i + 1\n",
    "            \n",
    "cm_df = pd.DataFrame(np.array(cm))\n",
    "gt_df = pd.DataFrame(np.array(gt))\n",
    "ss_df = pd.DataFrame(np.array(ss))\n",
    "ks_df = pd.DataFrame(np.array(ks))\n",
    "tm_df = pd.DataFrame(np.array(tm))\n",
    "nt_df = pd.DataFrame(np.array(nt))\n",
    "ns_df = pd.DataFrame(np.array(ns))\n",
    "pt_df = pd.DataFrame(np.array(pt))\n",
    "\n",
    "df = pd.concat([gt_df,ss_df,ks_df,nt_df,ns_df,tm_df,pt_df,cm_df],axis = 1)\n",
    "df.columns = ['GridType','SeedSpacing','k','nTrain','Superpixels','Time','TrainingPrSuperpixels','TP','FP','TN','FN']\n",
    "\n",
    "df['TotalPixels'] = df['TP'] + df['FP'] + df['FN'] + df['TN']\n",
    "df['SuperpixelsProportion'] = df['Superpixels']/df['TotalPixels']\n",
    "df['TrainingPrPixels'] = df['nTrain']/df['TotalPixels']\n",
    "\n",
    "df['FPR'] = df['FP']/(df['FP'] + df['TN'])\n",
    "df['FNR'] = df['FN']/(df['FN'] + df['TP'])\n",
    "df['Sensitivity'] = 1 - df['FNR']\n",
    "df['Specificity'] = 1 - df['FPR']\n",
    "\n",
    "df['FDR'] = df['FP']/(df['FP'] + df['TP'])\n",
    "df['FOR'] = df['FN']/(df['FN'] + df['TN'])\n",
    "df['Precision'] = 1 - df['FDR']\n",
    "df['NPV'] = 1 - df['FOR']\n",
    "\n",
    "df['Accuracy'] = (df['TP'] + df['TN'])/(df['TP'] + df['TN'] + df['FP'] + df['FN'])\n",
    "#df['MCC'] = ((df['TP'] * df['TN']) - (df['FP'] * df['FN']))/np.sqrt((df['TP'] + df['FP'])*(df['TP'] + df['FN'])*(df['TN'] + df['FP'])*(df['TN'] + df['FN']))\n",
    "#df['F1'] = 2*(df['Precision']*df['Sensitivity'])/(df['Precision'] + df['Sensitivity'])\n",
    "\n",
    "df.to_csv(\"C:/Users/Dave Mont/Desktop/Master_of_DataScience/TFM/Results/water_mask/cm_canelles_n.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0.1912200\n",
    "ymin = 42.1501858\n",
    "xmax = 0.2537043\n",
    "ymax = 42.3090388\n",
    "\n",
    "centerx = np.array([xmin,xmax]).mean()\n",
    "centery = np.array([ymin,ymax]).mean()\n",
    "\n",
    "ROI = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grado1 = ee.Image(\"COPERNICUS/S2_SR/20170814T105031_20170814T105517_T30TYM\")\n",
    "grado2 = ee.Image(\"COPERNICUS/S2_SR/20170913T105021_20170913T105335_T30TYM\")\n",
    "grado = ee.ImageCollection([grado1,grado2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grado = preprocessingPipeline(grado,ROI,masking = False,gapFilling = False)\n",
    "foliumLayer(grado,visRGBref,\"Preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDWI_grado = grado.normalizedDifference(['B3','B8'])\n",
    "truthMask_grado = NDWI_grado.gt(0)\n",
    "foliumLayer(truthMask_grado,{},\"WM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.batch.Export.image.toAsset(image = grado,description = \"Preprocessed_G\",assetId = \"users/dmlmont/TFM/Pre_Grado\",scale = 10,region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(grado,\n",
    "                                                                          ROI,\n",
    "                                                                          index = \"NDWI\",\n",
    "                                                                          seedSpacing = 10,\n",
    "                                                                          gridType = \"square\",\n",
    "                                                                          k = 4,\n",
    "                                                                          pTrain = 2)\n",
    "\n",
    "ee.batch.Export.image.toAsset(image = wm,description = \"WMp\",assetId = \"users/dmlmont/TFM/WMp_Grado\",scale = 10,region = ROI).start()\n",
    "ee.batch.Export.image.toAsset(image = truthMask_grado,description = \"WMt\",assetId = \"users/dmlmont/TFM/WMt_Grado\",scale = 10,region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(grado,\n",
    "                                                                          ROI,\n",
    "                                                                          index = \"NDWI\",\n",
    "                                                                          seedSpacing = 10,\n",
    "                                                                          gridType = \"square\",\n",
    "                                                                          k = 4,\n",
    "                                                                          pTrain = 2)\n",
    "\n",
    "cm, cm_image = imageConfusionMatrix(truthMask_grado,wm,ROI)\n",
    "\n",
    "toExport = [grado,wm,idx,SNIC,clusterImage,truthMask_grado,cm_image]\n",
    "prefix = [\"Preprocessed\",\"WMp\",\"Idx\",\"SNIC\",\"Clusters\",\"WMt\",\"CM\"]\n",
    "suffix = \"Grado\"\n",
    "toFilenames = []\n",
    "\n",
    "for p in prefix:\n",
    "    toFilenames.append(p + '_' + suffix)\n",
    "    \n",
    "for i in range(len(toExport)):\n",
    "    if i == 3:\n",
    "        ee.batch.Export.image.toDrive(image = toExport[i].toFloat(),\n",
    "                                      description = toFilenames[i],\n",
    "                                      folder = \"GEE\",\n",
    "                                      scale = 10,\n",
    "                                      region = ROI).start()\n",
    "    else:\n",
    "        ee.batch.Export.image.toDrive(image = toExport[i],\n",
    "                                      description = toFilenames[i],\n",
    "                                      folder = \"GEE\",\n",
    "                                      scale = 10,\n",
    "                                      region = ROI).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "gt = []\n",
    "ss = []\n",
    "ks = []\n",
    "cm = []\n",
    "tm = []\n",
    "nt = []\n",
    "ns = []\n",
    "pt = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for pTrain in [0.5,0.75,0.8,0.9,1,1.5,2]:\n",
    "    for gridType in [\"square\",\"hex\"]:\n",
    "        for seedSpacing in [10,20,30,40]:                    \n",
    "            for k in [3,4,5]:\n",
    "\n",
    "                print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "                print(\"-------> EMPIEZA NUMERO:\",i)\n",
    "                print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "\n",
    "                gt.append(gridType)\n",
    "                ss.append(seedSpacing)            \n",
    "                ks.append(k)\n",
    "                pt.append(pTrain)\n",
    "\n",
    "                start = time.time()\n",
    "                wm, idx, SNIC, X_train, clusterImage, ntrain, nseeds = automaticWaterMask(grado,\n",
    "                                                                                          ROI,\n",
    "                                                                                          index = \"NDWI\",\n",
    "                                                                                          seedSpacing = seedSpacing,\n",
    "                                                                                          gridType = gridType,\n",
    "                                                                                          k = k,\n",
    "                                                                                          pTrain = pTrain)\n",
    "                end = time.time()\n",
    "                print(end - start,\"s\")\n",
    "                tm.append(end - start)\n",
    "                nt.append(ntrain)\n",
    "                ns.append(nseeds)\n",
    "\n",
    "                cm.append(imageConfusionMatrix(truthMask_grado,wm,ROI))\n",
    "\n",
    "                i = i + 1\n",
    "            \n",
    "cm_df = pd.DataFrame(np.array(cm))\n",
    "gt_df = pd.DataFrame(np.array(gt))\n",
    "ss_df = pd.DataFrame(np.array(ss))\n",
    "ks_df = pd.DataFrame(np.array(ks))\n",
    "tm_df = pd.DataFrame(np.array(tm))\n",
    "nt_df = pd.DataFrame(np.array(nt))\n",
    "ns_df = pd.DataFrame(np.array(ns))\n",
    "pt_df = pd.DataFrame(np.array(pt))\n",
    "\n",
    "df = pd.concat([gt_df,ss_df,ks_df,nt_df,ns_df,tm_df,pt_df,cm_df],axis = 1)\n",
    "df.columns = ['GridType','SeedSpacing','k','nTrain','Superpixels','Time','TrainingPrSuperpixels','TP','FP','TN','FN']\n",
    "\n",
    "df['TotalPixels'] = df['TP'] + df['FP'] + df['FN'] + df['TN']\n",
    "df['SuperpixelsProportion'] = df['Superpixels']/df['TotalPixels']\n",
    "df['TrainingPrPixels'] = df['nTrain']/df['TotalPixels']\n",
    "\n",
    "df['FPR'] = df['FP']/(df['FP'] + df['TN'])\n",
    "df['FNR'] = df['FN']/(df['FN'] + df['TP'])\n",
    "df['Sensitivity'] = 1 - df['FNR']\n",
    "df['Specificity'] = 1 - df['FPR']\n",
    "\n",
    "df['FDR'] = df['FP']/(df['FP'] + df['TP'])\n",
    "df['FOR'] = df['FN']/(df['FN'] + df['TN'])\n",
    "df['Precision'] = 1 - df['FDR']\n",
    "df['NPV'] = 1 - df['FOR']\n",
    "\n",
    "df['Accuracy'] = (df['TP'] + df['TN'])/(df['TP'] + df['TN'] + df['FP'] + df['FN'])\n",
    "#df['MCC'] = ((df['TP'] * df['TN']) - (df['FP'] * df['FN']))/np.sqrt((df['TP'] + df['FP'])*(df['TP'] + df['FN'])*(df['TN'] + df['FP'])*(df['TN'] + df['FN']))\n",
    "#df['F1'] = 2*(df['Precision']*df['Sensitivity'])/(df['Precision'] + df['Sensitivity'])\n",
    "\n",
    "df.to_csv(\"C:/Users/Dave Mont/Desktop/Master_of_DataScience/TFM/Results/water_mask/cm_alto_grado_n.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE RESULTADOS DE MATRICES DE CONFUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_grado = pd.read_csv(\"C:/Users/Dave Mont/Desktop/Master_of_DataScience/TFM/Results/water_mask/cm_grado.csv\")\n",
    "melt_grado = pd.melt(cm_grado,id_vars=['GridType', 'SeedSpacing', 'k', 'TP', 'FP', 'TN', 'FN'],\n",
    "                     value_vars=['Accuracy','FPR', 'FNR', 'Sensitivity', 'Specificity'],\n",
    "                     var_name='Metric', value_name='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(melt_grado,row = \"Metric\", col = \"GridType\", margin_titles=True,sharey = False)\n",
    "g = g.map(sns.barplot,\"k\",\"Value\",\"SeedSpacing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "palette = sns.color_palette(\"colorblind\", 3)\n",
    "sns.lineplot(x=\"SeedSpacing\", y=\"Accuracy\",hue=\"k\", style=\"GridType\",data=cm_grado,palette = palette,markers=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4guNMUD-y00A"
   },
   "source": [
    "## PASO DE PRUEBA: CUMULATIVE COST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKniot4zy00A"
   },
   "outputs": [],
   "source": [
    "cumulativeCost = depthCumulativeCost(water_mask,ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "colab_type": "code",
    "id": "g057Y2jPy00F",
    "outputId": "e5121fce-76e6-428e-f839-8676c19d5dff"
   },
   "outputs": [],
   "source": [
    "foliumLayer(cumulativeCost,{\"min\":0,\"max\":400},\"CumCost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0S2TTNxhy00I"
   },
   "outputs": [],
   "source": [
    "bathy = loadBathymetry(\"C:/Users/Dave Mont/Desktop/Master_of_DataScience/TFM/bathymetric_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAk_dHiry00L"
   },
   "outputs": [],
   "source": [
    "water = S2_reduced.updateMask(water_mask)\n",
    "water = water.addBands(water.pixelLonLat())\n",
    "water = water.addBands(cumulativeCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwSKjs4ry00N",
    "outputId": "7ef4bb03-4377-43e2-ede0-f0639f72ef23"
   },
   "outputs": [],
   "source": [
    "water.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jEhAhZmy00P"
   },
   "outputs": [],
   "source": [
    "imageToReduce = water.select(['B2','B3','B4','B8','longitude','latitude','cumulative_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rn1KMxogy00R",
    "outputId": "0f52bd87-4618-44be-81ca-9b7f3115fcd1"
   },
   "outputs": [],
   "source": [
    "data = pixelDataFromCoordinates(imageToReduce,bathy)\n",
    "pd.set_option(\"display.precision\",15)\n",
    "data.columns = ['BatLon','BatLat','Profundidad','B2','B3','B4','B8','CumCost','PixLat','PixLon']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FFBDuDOy00U"
   },
   "outputs": [],
   "source": [
    "newPdData = pdData.astype({'BatLon':'float64',\n",
    "                          'BatLat':'float64',\n",
    "                          'Profundidad':'float64',\n",
    "                          'B2':'float64',\n",
    "                          'B3':'float64',\n",
    "                          'B4':'float64',\n",
    "                          'B8':'float64',\n",
    "                          'CumCost':'float64'}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDcG6hpIy00W"
   },
   "outputs": [],
   "source": [
    "dataMeans = newPdData.groupby(['PixLat','PixLon']).mean()\n",
    "dataStd = newPdData.groupby(['PixLat','PixLon']).std()\n",
    "dataCount = newPdData.groupby(['PixLat','PixLon']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xc4-lsTQy00Z",
    "outputId": "79260853-6e74-4f11-e6a4-990ae4c2b824"
   },
   "outputs": [],
   "source": [
    "dataMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALBfi0b2y00c",
    "outputId": "d9f04ff6-6d20-4ac0-d0bf-cf695f98f4f3"
   },
   "outputs": [],
   "source": [
    "plt.hist(dataCount['Profundidad'],bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vR7fYf8y00e",
    "outputId": "0f98e03a-891b-45ed-d7fe-9b5424cdc3b2"
   },
   "outputs": [],
   "source": [
    "plt.boxplot(dataCount['Profundidad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uw971jp2y00h",
    "outputId": "2843dcae-9989-4b76-e855-5f218a59c2ee"
   },
   "outputs": [],
   "source": [
    "plt.scatter(dataCount['Profundidad'],dataStd['Profundidad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g0d3qB94y00j",
    "outputId": "48fd5991-7d2c-4837-d034-ecf5a93664f4"
   },
   "outputs": [],
   "source": [
    "dataMeans.boxplot(column = ['B2','B3','B4','B8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D5BztwnZy00l"
   },
   "source": [
    "### Modelo Lineal (Usando la Razón Logarítmica (B2/B3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rn1WIAfTy00m",
    "outputId": "4606b532-530a-4386-f85c-ac25810ce85a"
   },
   "outputs": [],
   "source": [
    "X = np.array(np.log(dataMeans['B2'])/np.log(dataMeans['B3']))\n",
    "y = dataMeans['Profundidad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25,random_state=42)\n",
    "\n",
    "reg = LinearRegression().fit(X_train.reshape(-1, 1),y_train)\n",
    "\n",
    "scores = cross_val_score(LinearRegression(),X_train.reshape(-1, 1),y_train,cv = 5)\n",
    "print(\"Precisión del modelo: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "y_pred = reg.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "print(\"RMSE:\",mse(y_test,y_pred,squared = False))\n",
    "print(\"R2:\",r2(y_test,y_pred))\n",
    "\n",
    "plt.scatter(y_pred,y_test)\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_LDAkL6y00o"
   },
   "source": [
    "### Modelo lineal (Usando las cuatro bandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmio4IkAy00o",
    "outputId": "72e0f39a-2e10-45de-b8a3-cbc91b74b017"
   },
   "outputs": [],
   "source": [
    "X = dataMeans[['B2','B3','B4','B8']]\n",
    "y = dataMeans['Profundidad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25,random_state=42)\n",
    "\n",
    "scores = cross_val_score(LinearRegression(),X_train,y_train,cv = 10)\n",
    "print(\"Precisión del modelo: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "reg = LinearRegression().fit(X_train,y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "print(\"RMSE:\",mse(y_test,y_pred,squared = False))\n",
    "print(\"R2:\",r2(y_test,y_pred))\n",
    "\n",
    "plt.scatter(y_pred,y_test)\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kl8Aoc-2y00q"
   },
   "source": [
    "### Modelo de Procesos Gausianos (Usando las cuatro bandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-nSybWcy00r",
    "outputId": "25474a77-e488-4eb0-e50a-75bc4de8ce7e"
   },
   "outputs": [],
   "source": [
    "gp_kernel = C(1.0,(1e-4, 1e4)) * RBF(1,(1e-4, 1e4)) + WhiteKernel(1,(1e-4,1e4))\n",
    "gp = GaussianProcessRegressor(kernel=gp_kernel,n_restarts_optimizer=10)\n",
    "\n",
    "gp.fit(X_train,y_train)\n",
    "\n",
    "print(\"GPML kernel: %s\" % gp.kernel_)\n",
    "print(\"Log-marginal-likelihood: %.3f\" % gp.log_marginal_likelihood(gp.kernel_.theta))\n",
    "\n",
    "y_pred,sigma = gp.predict(X_test,return_std=True)\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "print(\"RMSE:\",mse(y_test,y_pred,squared = False))\n",
    "print(\"R2:\",r2(y_test,y_pred))\n",
    "\n",
    "plt.scatter(y_pred,y_test)\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNhKdK6Sy00t"
   },
   "source": [
    "### Usando CumulativeCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jh67sfL6y00u",
    "outputId": "2860a6b0-4c31-4fdc-9192-cd63f0173b5b"
   },
   "outputs": [],
   "source": [
    "dataMeans.boxplot(column = ['B2','B3','B4','B8','CumCost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJ-TGDaby00x"
   },
   "outputs": [],
   "source": [
    "X = dataMeans[['B2','B3','B4','B8','CumCost']]\n",
    "y = dataMeans['Profundidad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25,random_state=42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8REkwlE8y000",
    "outputId": "82131e8f-e3c1-4d36-d34f-1f8231e8d787"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(LinearRegression(),X_train_scaled,y_train,cv = 10)\n",
    "print(\"Precisión del modelo: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "reg = LinearRegression().fit(X_train_scaled,y_train)\n",
    "y_pred = reg.predict(X_test_scaled)\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "print(\"RMSE:\",mse(y_test,y_pred,squared = False))\n",
    "print(\"R2:\",r2(y_test,y_pred))\n",
    "\n",
    "plt.scatter(y_pred,y_test)\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUXJ-UTgy005",
    "outputId": "af5ada1c-3fe5-4161-e5fd-02668e8776fd"
   },
   "outputs": [],
   "source": [
    "gp_kernel = C(1.0,(1e-4, 1e4)) * RBF(1,(1e-4, 1e4)) + WhiteKernel(1,(1e-4,1e4))\n",
    "gp = GaussianProcessRegressor(kernel=gp_kernel,n_restarts_optimizer=10)\n",
    "\n",
    "gp.fit(X_train_scaled,y_train)\n",
    "\n",
    "print(\"GPML kernel: %s\" % gp.kernel_)\n",
    "print(\"Log-marginal-likelihood: %.3f\" % gp.log_marginal_likelihood(gp.kernel_.theta))\n",
    "\n",
    "y_pred,sigma = gp.predict(X_test_scaled,return_std=True)\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "print(\"RMSE:\",mse(y_test,y_pred,squared = False))\n",
    "print(\"R2:\",r2(y_test,y_pred))\n",
    "\n",
    "plt.scatter(y_pred,y_test)\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_K9L77Ly00_",
    "outputId": "dec8ad78-1889-4a9e-9345-3cb7531d5bed"
   },
   "outputs": [],
   "source": [
    "the_x = (dataMeans['CumCost']/dataMeans['B3'])\n",
    "\n",
    "plt.scatter(dataMeans['CumCost'],dataMeans['Profundidad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JrnT8Rgy01C",
    "outputId": "7c67b166-7fb5-43dd-f72e-a82267e8943e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(pdData['CumCost'],pdData['Profundidad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gXkNmDVy01E",
    "outputId": "3dbdfcd9-6f76-47c3-ff65-1df07bb109a6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "n = 6000\n",
    "k = 8000\n",
    "plt.plot(range(n,k),pdData['Profundidad'].iloc[n:k])\n",
    "#plt.plot(range(n),pdData['Profundidad'].iloc[:n].rolling(10,center = True).mean())\n",
    "#plt.plot(range(n),pdData['Profundidad'].iloc[:n].rolling(20,center = True).mean())\n",
    "#plt.plot(range(n),pdData['Profundidad'].iloc[:n].rolling(30,center = True).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gIkl0M1y01H",
    "outputId": "4687b566-bf11-49e4-d9af-34f2216e4fb4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(120,100))\n",
    "plt.scatter(pdData['BatLon'],pdData['BatLat'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "water_storage.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
