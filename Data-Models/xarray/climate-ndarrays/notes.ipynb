{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agenda**\n",
    "\n",
    "- HadCRUT4\n",
    "- netCDF\n",
    "- CF Conventions\n",
    "- netCDF4-python\n",
    "\n",
    "**Install required libraries**\n",
    "\n",
    "`conda install netCDF4 xarray numpy matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We have learned numpy, a low level tool to deal with multidimensional arrays. Today we will see how higher level tools integrate with numpy to work with multidimensional data in the context of meteorology.\n",
    "\n",
    "Also, we have worked with Numpy arrays in memory, these arrays disappear when the program ends. We will see how to persist multidimensional data using netCDF but don't forget that numpy arrays can be saved to disk using [numpy.save](https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html). The binary format is described [here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.lib.format.html#module-numpy.lib.format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HadCRUT4 Dataset\n",
    "\n",
    " HadCRUT4 is a global temperature dataset, providing gridded temperature anomalies across the world as well as averages for the hemispheres and the globe as a whole. CRUTEM4 and HadSST3 are the land and ocean components of this overall dataset, respectively.\n",
    "\n",
    "These datasets have been developed by the Climatic Research Unit (University of East Anglia) in conjunction with the Hadley Centre (UK Met Office), apart from the sea surface temperature (SST) dataset which was developed solely by the Hadley Centre. These datasets will be updated at roughly monthly intervals into the future. Hemispheric and global averages as monthly and annual values are available as separate files. \n",
    "\n",
    "- [HadCRUT4 Dataset](https://crudata.uea.ac.uk/cru/data/temperature/)\n",
    "- [CRUTEM4 Dataset](https://www.metoffice.gov.uk/hadobs/crutem4/)\n",
    "- [HadSST3 Hadley Centre SST Dataset](https://www.metoffice.gov.uk/hadobs/hadsst3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [netCDF](https://www.unidata.ucar.edu/software/netcdf/docs/netcdf_introduction.html)\n",
    "\n",
    "The Network Common Data Form, or netCDF, is an interface to a library of data access functions for storing and retrieving data in the form of arrays. An array is an n-dimensional (where n is 0, 1, 2, ...) rectangular structure containing items which all have the same data type (e.g., 8-bit character, 32-bit integer). A scalar (simple single value) is a 0-dimensional array.\n",
    "\n",
    "NetCDF is an abstraction that supports a view of data as a collection of self-describing, portable objects that can be accessed through a simple interface. Array values may be accessed directly, without knowing details of how the data are stored. Auxiliary information about the data, such as what units are used, may be stored with the data. Generic utilities and application programs can access netCDF datasets and transform, combine, analyze, or display specified fields of the data. The development of such applications has led to improved accessibility of data and improved re-usability of software for array-oriented data management, analysis, and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h 'absolute.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the following questions related to `absolute.nc`**\n",
    "\n",
    "- How many dimensions has the dataset? Which are their names?\n",
    "\n",
    "\n",
    "\n",
    "- How many variables has the dataset? Which are their names?\n",
    "\n",
    "\n",
    "\n",
    "- How many coordinate variables has the dataset? Which are their names?\n",
    "\n",
    "\n",
    "\n",
    "- Which units are used for measuring temperature?\n",
    "\n",
    "\n",
    "\n",
    "- How many temperature values (tem variable) has `absolute.nc` got?\n",
    "\n",
    "\n",
    "\n",
    "- Why there are only 12 values in the time variable if data is monthly?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ncdump -h 'HadCRUT.4.6.0.0.median.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Chunking](https://www.unidata.ucar.edu/blogs/developer/entry/chunking_data_why_it_matters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote netCDF\n",
    "\n",
    "See [OpenDAP (Data Access Protocol)](https://www.unidata.ucar.edu/software/netcdf/docs/dap2.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ncdump -h 'https://thredds.ucar.edu/thredds/dodsC/nws/metar/ncdecoded/files/Surface_METAR_20191007_0000.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CF conventions\n",
    "\n",
    "[CF conventions](http://cfconventions.org/) are designed to promote the processing and sharing of files created with the NetCDF API. The CF conventions are increasingly gaining acceptance and have been adopted by a number of projects and groups as a primary standard. The conventions define metadata that provide a definitive description of what the data in each variable represents, and the spatial and temporal properties of the data. This enables users of data from different sources to decide which quantities are comparable, and facilitates building applications with powerful extraction, regridding, and display capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netCDF4-python\n",
    "\n",
    "[netcdf4-python](http://unidata.github.io/netcdf4-python/netCDF4/index.html) is a Python interface to the netCDF C library.\n",
    "\n",
    "netCDF version 4 has many features not found in earlier versions of the library and is implemented on top of HDF5. This module can read and write files in both the new netCDF 4 and the old netCDF 3 format, and can create files that are readable by HDF5 clients. The API modelled after Scientific.IO.NetCDF, and should be familiar to users of that module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = nc4.Dataset('HadCRUT.4.6.0.0.median.nc')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = ds.variables['temperature_anomaly']\n",
    "print(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(ta[-1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_data = ta[:].data\n",
    "print(f'Type: {type(ta_data)}')\n",
    "print(f'Shape: {ta_data.shape}')\n",
    "print(f'Ndim: {ta_data.ndim}')\n",
    "print(f'Dtype: {ta_data.dtype}')\n",
    "print(f'Flags:\\n{ta_data.flags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "- Print the value of the maximun anomaly\n",
    "- Print the indices of the numpy array where the value is located (check with `ta_data[X,Y,Z]`)\n",
    "- Convert from Kelvin to Celsius and print the maximun anomaly (`C=K-273.15`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray\n",
    "\n",
    "[xarray](http://xarray.pydata.org/en/stable/index.html) (formerly xray) is an open source project and Python package that makes working with labelled multi-dimensional arrays simple, efficient, and fun!\n",
    "\n",
    "Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. The package includes a large and growing library of domain-agnostic functions for advanced analytics and visualization with these data structures.\n",
    "\n",
    "Xarray is inspired by and borrows heavily from pandas, the popular data analysis package focused on labelled tabular data. It is particularly tailored to working with netCDF files, which were the source of xarrayâ€™s data model, and integrates tightly with dask for parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadcrut4 = xr.open_dataset('HadCRUT.4.6.0.0.median.nc')\n",
    "print(hadcrut4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet\n",
    "\n",
    "[DataSet](http://xarray.pydata.org/en/stable/data-structures.html#dataset) is xarrayâ€™s multi-dimensional equivalent of a DataFrame. It is a dict-like container of labeled arrays (DataArray objects) with aligned dimensions. It is designed as an in-memory representation of the data model from the netCDF file format.\n",
    "\n",
    "### DataArray\n",
    "\n",
    "[DataArray](http://xarray.pydata.org/en/stable/data-structures.html#dataarray) is xarrayâ€™s implementation of a labeled, multi-dimensional array. It has several key properties:\n",
    "\n",
    "- values: a numpy.ndarray holding the arrayâ€™s values\n",
    "- dims: dimension names for each axis (e.g., ('x', 'y', 'z'))\n",
    "- coords: a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings)\n",
    "- attrs: dict to hold arbitrary metadata (attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(hadcrut4))\n",
    "print(type(hadcrut4.latitude))\n",
    "print(type(hadcrut4.longitude))\n",
    "print(type(hadcrut4.time))\n",
    "print(type(hadcrut4.temperature_anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hadcrut4.time) # Note how xarray interprets time values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hadcrut4.temperature_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hadcrut4.temperature_anomaly.values) # numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matplotlib integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = hadcrut4.temperature_anomaly.sel(time=hadcrut4.time[-1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global temperature anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = hadcrut4.temperature_anomaly.resample(time='1Y').mean()\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## 1 - Get the date for the min and max anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "(numpy.datetime64('1862-12-31T00:00:00.000000000'),\n",
    " numpy.datetime64('2016-12-31T00:00:00.000000000'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Plot anomalies for northen and southern poles (Hint: [where](http://xarray.pydata.org/en/stable/indexing.html#masking-with-where))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Get temperature values used to calculate anomalies in 2018 (as a numpy array (.values))\n",
    "\n",
    "**Look at temperature units**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute = xr.open_dataset('absolute.nc')\n",
    "print(absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(absolute.tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(t2018[~np.isnan(t2018)].sum(), t2018[~np.isnan(t2018)].max()) # 6214262.5, 310.1098"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
