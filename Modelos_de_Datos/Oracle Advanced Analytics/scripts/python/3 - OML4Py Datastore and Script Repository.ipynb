{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle Machine Learning for Python - Datastore and Script Repository\n",
    "Oracle Machine Learning for Python (OML4Py), a component of the Oracle Advanced Analytics option to Oracle Database Enterprise Edition, makes the open source Python scripting language and environment ready for the enterprise and big data. Designed for problems involving both large and small volumes of data, Oracle Machine Learning for Python integrates Python with Oracle Database, allowing users to execute Python commands and scripts for statistical, machine learning, and graphical analyses on database tables and views using Python syntax. Many familiar Python functions are overloaded and translate Python functions into SQL for in-database execution, as well as new automated machine learning capabilities. \n",
    "![title](img/OML4P_icon.jpg)\n",
    "In this notebook, we highlight the datastore and script repository features of OML4Py. \n",
    "\n",
    "With a datastore, you can store Python objects, which you can then use in subsequent Python sessions and even make those objects available to other users or programs by granting/revoking read permissions.\n",
    "\n",
    "Python objects, including OML4Py proxy objects, exist for the duration of the current Python session unless you explicitly save them. You can save one or more Python objects, including oml proxy objects, to a named datastore and then load those objects in a later Python session, including when using embedded Python execution. Datastores exist in the userâ€™s Oracle Database schema. A datastore, and the objects it contains, persist in the database until explicitly deleted.\n",
    "\n",
    "Using a datastore, you can:\n",
    "\n",
    "* Save OML4Py and other Python objects in one Python session and load them in another Python session\n",
    "* Pass non-scalar arguments to Python functions for use in embedded Python execution from the Python, but more importantly, from the SQL API\n",
    "* List available datastores and explore the contents of a datastore\n",
    "\n",
    "With the script repository, users can:\n",
    "\n",
    "* Create and store user-defined Python functions as scripts in Oracle Database\n",
    "* Grant or revoke the read privilege to a script\n",
    "* List available scripts\n",
    "* Load a script function into the Python environment\n",
    "* Drop a script from the script repository\n",
    "\n",
    "OML4Py has both a Python and SQL interface for creating and managing scripts in the script repository. You can make scripts either private or global. A private script is available only to the owner. A global script is available to any user. For private scripts, the owner of the script may grant the read privilege to other users or revoke that privilege."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Oracle Database\n",
    "To use OML4Py, first import the package ***oml***. OML4Py supports a variety of connection specification options, including Oracle Wallet. Once connected to an Oracle Database that has OML4Py installed, invoking ***oml.isconnected*** returns true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import oml\n",
    "oml.connect(user=\"pyquser\",password=\"Welcome1#Welcome1#\",dsn='(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=130.61.241.158)(PORT=1521))(CONNECT_DATA=(service_name=pdb1.sub12041412510.bdcevcn.oraclevcn.com)))')\n",
    "oml.isconnected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Pandas DataFrame objects and load into Oracle Database\n",
    "We load three data sets, combining target and predictors into a single DataFrame, before invoking ***create*** and displaying the columns for each. These will be used in exploring _datastore_ functionality.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEPAL_LENGTH', 'SEPAL_WIDTH', 'PETAL_LENGTH', 'PETAL_WIDTH', 'Species']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "\n",
    "# Load three data sets and create oml.DataFrame objects for them.\n",
    "iris = datasets.load_iris()\n",
    "x = pd.DataFrame(iris.data, columns = ['SEPAL_LENGTH','SEPAL_WIDTH',\n",
    "                                       'PETAL_LENGTH','PETAL_WIDTH'])\n",
    "y = pd.DataFrame(list(map(lambda x: {0: 'setosa', 1: 'versicolor',\n",
    "                 2:'virginica'}[x], iris.target)), columns = ['Species'])\n",
    "try:\n",
    "    oml.drop(table='IRIS')\n",
    "except:\n",
    "    pass\n",
    "IRIS = oml.create(pd.concat([x, y], axis=1), table = 'IRIS')\n",
    "iris = pd.concat([x, y], axis=1)\n",
    "print(IRIS.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'disease_progression']\n"
     ]
    }
   ],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "x = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "y = pd.DataFrame(diabetes.target, columns=['disease_progression'])\n",
    "\n",
    "DIABETES_TMP = oml.push(pd.concat([x, y], axis=1))\n",
    "print(DIABETES_TMP.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'Value']\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "x = pd.DataFrame(boston.data, columns = boston.feature_names.tolist())\n",
    "y = pd.DataFrame(boston.target, columns = ['Value'])\n",
    "\n",
    "BOSTON_TMP = oml.push(pd.concat([x, y], axis=1))\n",
    "print(BOSTON_TMP.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the actual _iris_ data and the temporary BOSTON proxy object to a datastore named \"ds_pydata\", overwriting if the named datastore already exists. Note that you can store actual data objects in a datastore, but large data objects should remain as database tables for performance and scalability. \n",
    "\n",
    "By storing the BOSTON_TMP object, the temporary table will not be deleted when the session terminates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.save(objs={'iris':iris, 'oml_boston':BOSTON_TMP},\n",
    "            name=\"ds_pydata\", description = \"python datasets\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a third object, the temporary DIABETES proxy object, to that same datastore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.save(objs={'oml_diabetes':DIABETES_TMP},\n",
    "                  name=\"ds_pydata\", append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the _iris_ DataFrame to a new datastore, and then list the datastores. Notice we see the datastore name, the number of objects in the datastore, the size in bytes consumed, when the datastore was create/updated, and any description provided by the user. Our two datastores _ds_iris_data_ and _ds_pydata_ are present, with the latter containing three objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.save(objs={'iris':iris},\n",
    "            name=\"ds_iris_data\", description = \"iris dataset\", overwrite=True)\n",
    "\n",
    "oml.ds.dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate storing other types of objects in datastores, we'll create regression models using sklearn and OML4Py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr1 = linear_model.LinearRegression()\n",
    "regr1.fit(boston.data, boston.target)\n",
    "\n",
    "regr2 = oml.glm(\"regression\")\n",
    "X = BOSTON_TMP.drop('Value')\n",
    "y = BOSTON_TMP['Value']\n",
    "regr2 = regr2.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save objects to a datastore and allow the read privilege to be granted to them. Then grant the read privilege to the datastore to all users by specifying ***user=None***. Finally list the datastores to which the read privilege has been granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.save(objs={'regr1':regr1, 'regr2':regr2},\n",
    "            name=\"ds_pymodel\", grantable=True, overwrite=True)\n",
    "\n",
    "oml.ds.dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.grant(name=\"ds_pymodel\", typ=\"datastore\", user=None)\n",
    "\n",
    "oml.ds.dir(dstype=\"grant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all Python objects from a datastore to the global workspace and sort the result by name. Notice that they have the name specified in the dictionary when saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(oml.ds.load(name=\"ds_pydata\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the named Python object, regr2, from the datastore to the global workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.load(name=\"ds_pymodel\", objs=[\"regr2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the named Python object, regr1, from the datastore to the user's workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.load(name=\"ds_pymodel\", objs=[\"regr1\"], to_globals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all saved datastores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.dir(dstype=\"all\")[['owner', 'datastore_name', 'object_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then show datastores to which other users have been granted the read privilege."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.dir(dstype=\"grant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, show datastores to which this user has been granted the read privilege (there currently are none)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.dir(dstype=\"granted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, show datastores whose names match a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.dir(name='pydata', regex_match=True)[['datastore_name', 'object_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's describe the contents of the ds_pydata datastore. Notice that the three proxy objects are listed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.describe(name='ds_pydata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revoke the read privilege from every user, and again show datastores to which read privilege has been granted. The result is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.revoke(name=\"ds_pymodel\", typ=\"datastore\", user=None)\n",
    "\n",
    "oml.ds.dir(dstype=\"grant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grant the read privilege to the user PYQUSER2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.grant(name=\"ds_pymodel\", typ=\"datastore\", user=\"PYQUSER2\")\n",
    "\n",
    "oml.ds.dir(dstype=\"grant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete some objects from the datastore.\n",
    "Delete a datastore.\n",
    "Delete all datastores whose names match a pattern.\n",
    "Show the existing datastores again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.ds.delete(name=\"ds_pydata\", objs=[\"iris\", \"oml_boston\"])\n",
    "\n",
    "oml.ds.delete(name=\"ds_pydata\")\n",
    "\n",
    "oml.ds.delete(name=\"_pymodel\", regex_match=True)\n",
    "\n",
    "oml.ds.dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Script Repository\n",
    "\n",
    "To illustrate using the Python Script Repository, we first define a function ***build_lm1*** that will fit a regression model. With this function, we create a script named \"MyLM_function\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x = pd.DataFrame(iris.data, columns = ['SEPAL_LENGTH','SEPAL_WIDTH',\n",
    "                                       'PETAL_LENGTH','PETAL_WIDTH'])\n",
    "y = pd.DataFrame(list(map(lambda x: {0: 'setosa', 1: 'versicolor',\n",
    "                          2:'virginica'}[x], iris.target)), \n",
    "                 columns = ['Species'])\n",
    "IRIS2 = oml.push(pd.concat([x, y], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lm1(dat):\n",
    "    from sklearn import linear_model\n",
    "    regr = linear_model.LinearRegression()\n",
    "    import pandas as pd\n",
    "    dat = pd.get_dummies(dat, drop_first=True)\n",
    "    X = dat[[\"SEPAL_WIDTH\", \"PETAL_LENGTH\", \"PETAL_WIDTH\", \n",
    "             \"Species_versicolor\", \"Species_virginica\"]]\n",
    "    y = dat[[\"SEPAL_LENGTH\"]]\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "oml.script.create(\"MyLM_function\", func=build_lm1, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the scripts available only to the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oml.script.dir(sctype='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grant the read privilege to the MyLM_function script to the user PYQUSER2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.grant(name=\"MyLM_function\", typ=\"pyqscript\", user=\"PYQUSER2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the scripts to which read privilege has been granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.script.dir(sctype=\"grant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revoke the read privilege to the MyLM_function script from the user PYQUSER2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.revoke(name=\"MyLM_function\", typ=\"pyqscript\", user=\"PYQUSER2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use embedded Python execution to invoke this function. First we ***sync*** the IRIS table to get a proxy object, then use ***table_apply***, providing the proxy object, function name and the output type. We'll view the result and then pull the coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = oml.table_apply(IRIS2, func=\"MyLM_function\", \n",
    "                      oml_input_type=\"pandas.DataFrame\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.pull().coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define and save another function ***build_lm2***, but this time as global. We'll then invoke that function to build another model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lm2(dat):\n",
    "  from sklearn import linear_model\n",
    "  regr = linear_model.LinearRegression()\n",
    "  X = dat[[\"PETAL_WIDTH\"]]\n",
    "  y = dat[[\"PETAL_LENGTH\"]]\n",
    "  regr.fit(X, y)\n",
    "  return regr\n",
    "\n",
    "oml.script.create(\"MyGlobalLM_function\", func=build_lm2, is_global=True, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = oml.table_apply(IRIS, func=\"MyGlobalLM_function\", \n",
    "                      oml_input_type=\"pandas.DataFrame\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the scripts in the script repository available to the current user only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.script.dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all of the scripts available to the current user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.script.dir(sctype='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the scripts available to all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.script.dir(sctype='global')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MyLM_function and MyGlobalLM_function scripts, and pull the models to the local Python session. For MYLM, build the model in on the IRIS data set and pull the coefficients.  For GlobalMYLM, build and display the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYLM = oml.script.load(name=\"MyLM_function\")\n",
    "GlobalMYLM = oml.script.load(name=\"MyGlobalLM_function\")\n",
    "\n",
    "print(\"Coefficients: \", MYLM(IRIS.pull()).coef_)\n",
    "print(\"Model: \", GlobalMYLM(IRIS.pull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the available scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.script.dir(sctype=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the private script.\n",
    "\n",
    "Drop the global script.\n",
    "\n",
    "List the available scripts again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.script.drop(\"MyLM_function\")\n",
    "oml.script.drop(\"MyGlobalLM_function\", is_global=True)\n",
    "oml.script.dir(sctype=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Oracle-sm.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
