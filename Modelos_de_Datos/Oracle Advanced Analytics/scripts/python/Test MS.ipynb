{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle Machine Learning for Python - Data Selection and Manipulation\n",
    "Oracle Machine Learning for Python (OML4Py), a component of the Oracle Advanced Analytics option to Oracle Database Enterprise Edition, makes the open source Python scripting language and environment ready for the enterprise and big data. Designed for problems involving both large and small volumes of data, Oracle Machine Learning for Python integrates Python with Oracle Database, allowing users to execute Python commands and scripts for statistical, machine learning, and graphical analyses on database tables and views using Python syntax. Many familiar Python functions are overloaded and translate Python functions into SQL for in-database execution, as well as new automated machine learning capabilities. \n",
    "![title](img/OML4P_icon.jpg)\n",
    "In this notebook, we highlight various features of the transparency layer for data selection and manipulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Oracle Database\n",
    "To use OML4Py, first import the package ***oml***. OML4Py supports a variety of connection specification options, including Oracle Wallet. Once connected to an Oracle Database that has OML4Py installed, invoking ***oml.isconnected*** returns true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import oml\n",
    "oml.connect(user=\"pyquser\",password=\"Cdoday19#Cdoday19#\",dsn='(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=130.61.241.158)(PORT=1521))(CONNECT_DATA=(service_name=pdb2.sub12041412510.bdcevcn.oraclevcn.com)))')\n",
    "oml.isconnected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import oml\n",
    "oml.connect(user=\"pyquser\",password=\"pyquser#123pyquser#123\",dsn='(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=130.61.60.94)(PORT=1521))(CONNECT_DATA=(service_name=pdb1.sub03010825490.devopsvcn.oraclevcn.com)))')\n",
    "oml.isconnected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a temporary OML DataFrame proxy object using ***push***. Then, select all rows with...\n",
    "* the specified column names\n",
    "* columns whose indices are in the range (1, 4)\n",
    "* columns of oml.String data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIZZA = oml.sync(view='V_PAYMENTS')\n",
    "PIZZA.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = pd.DataFrame(iris.data, columns = ['SEPAL_LENGTH','SEPAL_WIDTH',\n",
    "                                       'PETAL_LENGTH','PETAL_WIDTH'])\n",
    "y = pd.DataFrame(list(map(lambda x: {0: 'setosa', 1: 'versicolor', \n",
    "                          2:'virginica'}[x], iris.target)), \n",
    "                 columns = ['Species'])\n",
    "z = pd.concat([x, y], axis=1)\n",
    "\n",
    "IRIS_TMP = oml.push(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   SEPAL_LENGTH  PETAL_LENGTH\n",
       "0           5.1           1.4\n",
       "1           4.9           1.4\n",
       "2           4.7           1.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IRIS_projected1 = IRIS_TMP[:, [\"SEPAL_LENGTH\", \"PETAL_LENGTH\"]]\n",
    "IRIS_projected1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     SEPAL_LENGTH  SEPAL_WIDTH  PETAL_LENGTH  PETAL_WIDTH    Species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "5             5.4          3.9           1.7          0.4     setosa\n",
       "6             4.6          3.4           1.4          0.3     setosa\n",
       "7             5.0          3.4           1.5          0.2     setosa\n",
       "8             4.4          2.9           1.4          0.2     setosa\n",
       "9             4.9          3.1           1.5          0.1     setosa\n",
       "10            5.4          3.7           1.5          0.2     setosa\n",
       "11            4.8          3.4           1.6          0.2     setosa\n",
       "12            4.8          3.0           1.4          0.1     setosa\n",
       "13            4.3          3.0           1.1          0.1     setosa\n",
       "14            5.8          4.0           1.2          0.2     setosa\n",
       "15            5.7          4.4           1.5          0.4     setosa\n",
       "16            5.4          3.9           1.3          0.4     setosa\n",
       "17            5.1          3.5           1.4          0.3     setosa\n",
       "18            5.7          3.8           1.7          0.3     setosa\n",
       "19            5.1          3.8           1.5          0.3     setosa\n",
       "20            5.4          3.4           1.7          0.2     setosa\n",
       "21            5.1          3.7           1.5          0.4     setosa\n",
       "22            4.6          3.6           1.0          0.2     setosa\n",
       "23            5.1          3.3           1.7          0.5     setosa\n",
       "24            4.8          3.4           1.9          0.2     setosa\n",
       "25            5.0          3.0           1.6          0.2     setosa\n",
       "26            5.0          3.4           1.6          0.4     setosa\n",
       "27            5.2          3.5           1.5          0.2     setosa\n",
       "28            5.2          3.4           1.4          0.2     setosa\n",
       "29            4.7          3.2           1.6          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "120           6.9          3.2           5.7          2.3  virginica\n",
       "121           5.6          2.8           4.9          2.0  virginica\n",
       "122           7.7          2.8           6.7          2.0  virginica\n",
       "123           6.3          2.7           4.9          1.8  virginica\n",
       "124           6.7          3.3           5.7          2.1  virginica\n",
       "125           7.2          3.2           6.0          1.8  virginica\n",
       "126           6.2          2.8           4.8          1.8  virginica\n",
       "127           6.1          3.0           4.9          1.8  virginica\n",
       "128           6.4          2.8           5.6          2.1  virginica\n",
       "129           7.2          3.0           5.8          1.6  virginica\n",
       "130           7.4          2.8           6.1          1.9  virginica\n",
       "131           7.9          3.8           6.4          2.0  virginica\n",
       "132           6.4          2.8           5.6          2.2  virginica\n",
       "133           6.3          2.8           5.1          1.5  virginica\n",
       "134           6.1          2.6           5.6          1.4  virginica\n",
       "135           7.7          3.0           6.1          2.3  virginica\n",
       "136           6.3          3.4           5.6          2.4  virginica\n",
       "137           6.4          3.1           5.5          1.8  virginica\n",
       "138           6.0          3.0           4.8          1.8  virginica\n",
       "139           6.9          3.1           5.4          2.1  virginica\n",
       "140           6.7          3.1           5.6          2.4  virginica\n",
       "141           6.9          3.1           5.1          2.3  virginica\n",
       "142           5.8          2.7           5.1          1.9  virginica\n",
       "143           6.8          3.2           5.9          2.3  virginica\n",
       "144           6.7          3.3           5.7          2.5  virginica\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IRIS_projected2 = IRIS_TMP[:, 1:4]\n",
    "IRIS_projected2.head(3)\n",
    "oml.create(z,'IRIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS_projected3 = IRIS_TMP.select_types(include=[oml.String])\n",
    "IRIS_projected3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID   RES\n",
       "0   0  0.00\n",
       "1   1  0.01\n",
       "2   2  0.02\n",
       "3   3  0.03\n",
       "4   4  0.04\n",
       "5   5  0.05\n",
       "6   6  0.06\n",
       "7   7  0.07\n",
       "8   8  0.08\n",
       "9   9  0.09"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_df(num, scale):\n",
    "    import pandas as pd\n",
    "    id = list(range(0,int(num)))\n",
    "    res = [i/scale for i in id]\n",
    "    return pd.DataFrame({\"ID\":id, \"RES\":res})\n",
    "res = oml.do_eval(func=return_df, func_value=pd.DataFrame({\"ID\":[0],\"RES\":[0]}), scale=100, num=10)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore various ways of filtering data in-database. \n",
    "* select sepal length and petal length where petal length is less than 1.5\n",
    "* select all rows in which petal length is less than 1.5 or sepal length is 5.0, using the AND and OR conditions in filtering\n",
    "* select all rows in which petal length is less than 1.5 and sepal length is larger than 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS_filtered1 = IRIS_TMP[IRIS_TMP[\"PETAL_LENGTH\"] < 1.5, \n",
    "                                  [\"SEPAL_LENGTH\", \"PETAL_LENGTH\"]]\n",
    "print(\"Length: \", len(IRIS_filtered1))\n",
    "IRIS_filtered1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS_filtered2 = IRIS_TMP[(IRIS_TMP[\"PETAL_LENGTH\"] < 1.5) | \n",
    "                          (IRIS_TMP[\"SEPAL_LENGTH\"] == 5.0), :]\n",
    "print(\"Length: \", len(IRIS_filtered2))\n",
    "IRIS_filtered2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS_filtered3 = IRIS_TMP[(IRIS_TMP[\"PETAL_LENGTH\"] < 1.5) & \n",
    "                          (IRIS_TMP[\"SEPAL_LENGTH\"] > 5.0), :]\n",
    "print(\"Length: \", len(IRIS_filtered3))\n",
    "IRIS_filtered3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pandas DataFrame objects\n",
    "Let's explore operations involving Pandas DataFrames. \n",
    "\n",
    "We'll start by creating a temporary table from a Pandas DataFrame and use the ***append*** function. First, append an oml.Float series object to another, then append an oml.DataFrame object to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame({\"id\" : [1, 2, 3, 4, 5],\n",
    "                      \"val\" : [\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "                      \"ch\" : [\"p\", \"q\", \"r\", \"a\", \"b\"],\n",
    "                      \"num\" : [4, 3, 6.7, 7.2, 5]})\n",
    "MY_DF = oml.push(my_df)\n",
    "\n",
    "print (my_df.dtypes)\n",
    "\n",
    "num1 = MY_DF['id']\n",
    "num2 = MY_DF['num']\n",
    "num1.append(num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MY_DF[['id', 'val']] \n",
    "y = MY_DF[['num', 'ch']] \n",
    "\n",
    "print(x.dtypes)\n",
    "print(y.dtypes)\n",
    "\n",
    "x.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try a few examples using the ***concat*** function.\n",
    "* create two oml.DataFrame objects and combine the objects column-wise\n",
    "* create an oml.Float object with the rounded exponential of two times the values in the num column of the oml_frame object, then concatenate it with the oml.DataFrame object y using a new column name\n",
    "* concatenate object x with multiple objects and turn on automatic name conflict resolution\n",
    "* concatenate multiple OML data objects and perform customized renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "x = MY_DF[['id', 'val']]\n",
    "y = MY_DF[['num', 'ch']]\n",
    "x.concat(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = (MY_DF['num']*2).exp().round(decimals=2)\n",
    "y.concat({'round(exp(2*num))':w})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = MY_DF[:,'id']\n",
    "x.concat([z, w, y], auto_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.concat(OrderedDict([('ID',z), ('round(exp(2*num))',w), ('New_',y)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore merging data. Perform:\n",
    "* cross join\n",
    "* left outer join\n",
    "* right outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MY_DF[['id', 'val']]\n",
    "y = MY_DF[['num', 'ch']]\n",
    "\n",
    "z = x.merge(y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(4).merge(other=MY_DF[['id', 'num']], on=\"id\", suffixes=['.l','.r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.merge(other=y, left_on=\"id\", right_on=\"num\", how=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try the _drop_ functonality with ***dropna***, ***drop_duplicates***, and ***drop***:\n",
    "* drop rows with any missing values\n",
    "* drop rows in which all column values are missing\n",
    "* drop rows in which any numeric column values are missing\n",
    "* drop duplicate rows\n",
    "* drop rows that have the same value in column 'string1' and 'string2'\n",
    "* drop column 'string2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df2 = pd.DataFrame({'numeric': [1, 1.4, -4, -4, 5.432, None, None],\n",
    "                   'string1' : [None, None, 'a', 'a', 'a', 'b', None],\n",
    "                   'string2': ['x', None, 'z', 'z', 'z', 'x', None]})\n",
    "MY_DF2 = oml.push(my_df2, dbtypes = {'numeric': 'BINARY_DOUBLE',\n",
    "                                     'string1':'CHAR(1)', \n",
    "                                     'string2':'CHAR(1)'})\n",
    "MY_DF2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF2.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF2.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF2.dropna(how='any', subset=['numeric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF2.drop_duplicates(subset=['string1', 'string2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF2.drop('string2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore the ***split*** and ***KFold*** function using the _digits_ data set. After creating an OML DataFrame proxy object for the _digits_ data set, \n",
    "* sample 20% and 80% of the data\n",
    "* split the data into four sets\n",
    "* perform stratification on the target column\n",
    "* verify that the stratified sampling generates splits in which all of the different categories of digits (digits 0~9) are present in each split\n",
    "* hash on the target column\n",
    "* verify that the different categories of digits (digits 0~9) are present in only one of the splits generated by hashing on the category column\n",
    "* split the data randomly into 4 consecutive folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "pd_digits = pd.DataFrame(digits.data,\n",
    "                         columns=['IMG'+str(i) for i in\n",
    "                         range(digits['data'].shape[1])])\n",
    "pd_digits = pd.concat([pd_digits,\n",
    "                       pd.Series(digits.target,\n",
    "                                  name = 'target')],\n",
    "                                  axis = 1)\n",
    "DIGITS = oml.push(pd_digits)\n",
    "print(\"Shape: \", DIGITS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = DIGITS.split(ratio=(.2, .8), use_hash = False)\n",
    "print(\"Split lengths: \", [len(split) for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = DIGITS.split(ratio = (.25, .25, .25, .25), use_hash = False)\n",
    "print(\"Split lengths: \", [len(split) for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = DIGITS.split(strata_cols=['target'])\n",
    "print(\"Split lengths: \", [split.shape for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verify values: \", [split['target'].drop_duplicates().sort_values().pull()\n",
    "for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = DIGITS.split(hash_cols=['target'])\n",
    "print(\"Split lengths: \", [split.shape for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verify values: \", [split['target'].drop_duplicates().sort_values().pull()\n",
    "for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = DIGITS.KFold(n_splits=4)\n",
    "print(\"Split lengths: \", [(len(fold[0]), len(fold[1])) for fold in folds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore the ***corr*** function. We construct a trivial, highly correlated DataFrame. First, verify that the correlation between column A and B is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_df2 = pd.DataFrame({'A': range(4), 'B': [2*i for i in range(4)]})\n",
    "MY_DF2 = oml.push(my_df2)\n",
    "MY_DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a few changes to the data to alter the correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df3 = my_df2\n",
    "\n",
    "# Change a value to test the change in the computed correlation result\n",
    "my_df3.loc[2, 'A'] = 1.5\n",
    "\n",
    "# Change an entry to NaN (not a number) to test the 'skipna' parameter in corr\n",
    "my_df3.loc[1, 'B'] = None\n",
    "\n",
    "# Push my_df3 to Oracle Database using the floating point column type \n",
    "# because NaNs cannot be used in Oracle numbers\n",
    "MY_DF3 = oml.push(my_df3, oranumber=False)\n",
    "MY_DF3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, 'skipna' is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF3.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF3.corr(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore the ***crosstab*** and ***pivot*** functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df4 = pd.DataFrame({\n",
    "     'GENDER': ['M', 'M', 'F', 'M', 'F', 'M', 'F', 'F', None, 'F', 'M', 'F'],\n",
    "     'HAND': ['L', 'R', 'R', 'L', 'R', None, 'L', 'R', 'R', 'R', 'R', 'R'],\n",
    "     'SPEED': [40.5, 30.4, 60.8, 51.2, 54, 29.3, 34.1, 39.6, 46.4, 12, 25.3, 37.5],\n",
    "     'ACCURACY': [.92, .94, .87, .9, .85, .97, .96, .93, .89, .84, .91, .95]\n",
    "    })\n",
    "MY_DF4 = oml.push(my_df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the categories that the most entries belonged to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.crosstab('GENDER', 'HAND').sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each gender value and across all entries, find the ratio of entries with different hand values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.crosstab('GENDER', 'HAND', pivot = True, margins = True, normalize = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the mean speed across all gender and hand combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.pivot_table('GENDER', 'HAND', 'SPEED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the median accuracy and speed for every gender and hand combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.pivot_table('GENDER', 'HAND', aggfunc = oml.DataFrame.median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the max and min speeds for every gender and hand combination and across all combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.pivot_table('GENDER', 'HAND', 'SPEED', \n",
    "               aggfunc = [oml.DataFrame.max, oml.DataFrame.min],\n",
    "               margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore creating new columns using a simple shopping cart data set. Note, that using the transparency layer, all these computations occur in-database. Neither the input nor the result needs to be brought to the client Python engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_cart = pd.DataFrame({\n",
    "  'Item_name': ['paper_towel', 'ground_pork', 'tofu', 'eggs',\n",
    "                'pork_loin', 'whole_milk', 'egg_custard'],\n",
    "  'Item_type': ['grocery', 'meat', 'grocery', 'dairy', 'meat',\n",
    "                'dairy', 'bakery'],\n",
    "  'Quantity': [1, 2.6, 4, 1, 1.9, 1, 1],\n",
    "  'Unit_price': [1.19, 2.79, 0.99, 2.49, 3.19, 2.5, 3.99]\n",
    "  })\n",
    "CART = oml.push(shopping_cart)\n",
    "CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column 'Price' multiplying 'Quantity' with 'Unit_price', rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = CART['Quantity']*(CART['Unit_price'])\n",
    "print(\"Type: \", type(price))\n",
    "CART = CART.concat({'Price': price.round(2)})\n",
    "CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the pattern 'egg' in the 'Item_name' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_pattern = CART['Item_name'].count_pattern('egg')\n",
    "print(\"Type: \", type(egg_pattern))\n",
    "CART.concat({'Egg_pattern': egg_pattern})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the start index of substring 'pork' in the 'Item_name' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pork_startInd = CART['Item_name'].find('pork')\n",
    "print(\"Type: \", type(pork_startInd))\n",
    "CART.concat({'Pork_startInd': pork_startInd})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether items are of grocery category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_grocery=CART['Item_type']=='grocery'\n",
    "print(\"Type: \", type(is_grocery))\n",
    "CART.concat({'Is_grocery': is_grocery})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the length of item names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_length=CART['Item_name'].len()\n",
    "print(\"Type: \", type(name_length))\n",
    "CART.concat({'Name_length': name_length})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a few other function to modify the Price column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ceiling: \", CART['Price'].ceil())\n",
    "print(\"Floor: \", CART['Price'].floor())\n",
    "print(\"Exponential: \", CART['Price'].exp().round(3))\n",
    "print(\"logarithm: \", CART['Price'].log().round(3))\n",
    "print(\"Square Root: \", CART['Price'].sqrt().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using a modified version of the _iris_ data set, explore ***sort_values*** and ***tail*** functions. \n",
    "\n",
    "We modify the dataset by replacing a few entries with NaNs to test how the _na_position_ parameter works in the ***sort_values*** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = pd.DataFrame(iris.data, columns = ['Sepal_Length', 'Sepal_Width',\n",
    "                                       'Petal_Length', 'Petal_Width'])\n",
    "y = pd.DataFrame(list(map(lambda x: {0: 'setosa', 1: 'versicolor',\n",
    "                                     2:'virginica'}[x], iris.target)), \n",
    "                 columns = ['Species'])\n",
    "                   \n",
    "x['Sepal_Width'].replace({3.5: None}, inplace=True)\n",
    "x['Petal_Length'].replace({1.5: None}, inplace=True)\n",
    "x['Petal_Width'].replace({2.3: None}, inplace=True)\n",
    "\n",
    "iris_df = pd.concat([x, y], axis=1)\n",
    "IRIS2 = oml.push(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the data set first by Sepal_Length then by Sepal_Width in descending order and display the first 5 rows of the sorted result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS2.sort_values(by = ['Sepal_Length', 'Sepal_Width'],\n",
    "                  ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the last 5 rows of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the last 5 rows of the iris data set first by Petal_Length then by Petal_Width. By default, rows with NaNs are placed after the other rows when the sort keys are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS2.tail().sort_values(by = ['Petal_Length', 'Petal_Width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the last 5 rows of the IRIS data set first by Petal_Length and then by Petal_Width. When the values in these two columns are the same, place the row with a NaN before the other row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS2.tail().sort_values(by = ['Petal_Length', 'Petal_Width'], \n",
    "                                 na_position = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we explore column creation/renaming, describing data statistics, and computing a variety of statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df4 = pd.DataFrame({'numeric_col': [1, 1.4, -4, 3.145, 5, None],\n",
    "                       'string_col' : [None, None, 'a', 'a', 'a', 'b'],\n",
    "                       'bytes_col' : [b'a', b'b', b'c', b'c', b'd', b'e']})\n",
    "\n",
    "MY_DF4 = oml.push(my_df4, dbtypes = {'numeric_col': 'BINARY_DOUBLE',\n",
    "                                     'string_col':'CHAR(1)', \n",
    "                                     'bytes_col':'RAW(1)'})\n",
    "MY_DF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine a Boolean column with MY_DF4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml_bool = MY_DF4['numeric_col'] > 3\n",
    "\n",
    "MY_DF4 = MY_DF4.concat(oml_bool)\n",
    "MY_DF4.rename({'COL4':'boolean_col'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the ***describe*** function to compute a variety of statistics on all columns. Then, exclude the Float columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.describe(exclude=[oml.Float])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sum of values in each Float or Boolean column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the cumulative sum of values in each Float or Boolean column after MY_DF4 is sorted by the bytes column in descending order. Then, compute skew, median, and kurtosis for float columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.cumsum(by = 'bytes_col', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_DF4.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, explore the ***boxplot*** and ***hist*** functions using the _wine_ data set. The statistics supporting these plots are computed in-database, so transfer of data or memory limitations are avoided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "wine_data = pd.DataFrame(wine.data, columns = wine.feature_names)\n",
    "WINE = oml.push(wine_data)\n",
    "\n",
    "oml.graphics.boxplot(WINE[:,8:12], showmeans=True, \n",
    "                     meanline=True, patch_artist=True, \n",
    "                     labels=WINE.columns[8:12])\n",
    "plt.title('Distribution of Wine Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.graphics.hist(WINE['proline'], bins=10, color='red',\n",
    "                  linestyle='solid', edgecolor='black')\n",
    "plt.title('Proline content in Wine')\n",
    "plt.xlabel('proline content')\n",
    "plt.ylabel('# of wine instances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml.disconnect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Oracle-sm.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
