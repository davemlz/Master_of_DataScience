{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducción de la dimensión (lineal)\n",
    "_Santander Meteorology Group (15-01-2020)_\n",
    "\n",
    "En esta práctica vamos a continuar con la de la Sesión 10, en la que analizábamos la base de datos de cáncer de mama (breastcancer.csv, disponible en Moodle). Contiene características de los núcleos celulares extraídas de imágenes de biopsias. En la sesión 10 ya aplicamos técnicas de selección de valiables y de regularización a este conjunto de datos. En esta práctica se trata de aplicar técnicas proyectivas lineales de reducción de la dimensión: PCA y LDA.\n",
    "\n",
    "Utiliza el notebook de la sesión 10, donde ya habíamos cargado los datos y aplicado técnicas de selección de variables y de regularización. Crea secciones al final de ese notebook para realizar las tareas que se solicitan a continuación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Realiza un Análisis de Componentes Principales de las covariables de esta base de datos. Estudia el número óptimo de variables a considerar a la vista de un Scree plot (`? screeplot`). Utiliza un gráfico de varianza explicada acumulada para visualizar la fracción de varianza explicada por estas variables.\n",
    " \n",
    " 1. Un *biplot* (`? biplot`) permite visualizar tanto los *scores* (PCs) como los *loadings* (EOFs) proyectados sobre las dos primeras PCs. Represéntalo para esta base de datos.\n",
    " \n",
    " 1. El biplot es útil cuando el número de covariables no es muy elevado. Representa gráficamente los EOFs de esta base de datos, para poner de manifiesto su ortogonalidad y poder interpretar mejor las combinaciones lineales de covariables a las que dan lugar.\n",
    " \n",
    " 1. Representa también una de las muestras, junto con su reconstrucción mediante las *r* primeras PCs\n",
    " \n",
    " 1. Realiza un Análisis Discriminante Lineal sobre esta base de datos. En este caso, se trata de una técnica de aprendizaje supervisado, en la que involucramos la variable respuesta en la elección de direcciones de proyección de los datos.\n",
    " \n",
    " 1. Representa la distribución de los datos a lo largo de la dirección dada por el primer LD\n",
    " \n",
    " 1. Realiza una tabla de contingencia para estudiar la pericia de este método lineal de clasificación\n",
    " \n",
    " 1. El LDA proporciona una predicción probabilista de las clases, ya que esta técnica implementa un clasificador bayesiano, basado en las probabilidades a posteriori de pertenencia a cada clase, bajo la hipótesis de normalidad. Utilizar una técnica de validación probabilista, como las curva ROC para evaluar la pericia de esta predicción probabilista.\n",
    " \n",
    " 1. Repetir lo anterior pero mediante una valiadación cruzada tipo *hold out*, para ver la capacidad de generalización de esta técnica lineal.\n",
    " \n",
    " 1. Repetir todos los pasos de esta práctica para otra base de datos de tu elección. Para visualizar mejor los resultados es preferible que no tenga demasiadas covariables, como por ejemplo `ISLR::Hitters` o `USArrests` (consulta la ayuda para ver de qué se trata)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
