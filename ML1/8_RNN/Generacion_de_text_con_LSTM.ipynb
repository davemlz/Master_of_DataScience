{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Generacion_de_text_con_LSTM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWWwep8Elju_",
        "colab_type": "code",
        "outputId": "8b2fee75-3c84-4632-ac2b-e07366f1a799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KRE0k-aljvE",
        "colab_type": "text"
      },
      "source": [
        "# Text generation with a LSTM\n",
        "\n",
        "We are going to implement a LSTM in Keras. The first thing we need is a big amount of text to be able to learn a linguistic model. One can use any big text file. In this example we are going to be using El Quijote. Our model will learn a specific model based on the writting style of Cervantes in this particular book.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCQtJ_COljvF",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the data\n",
        "\n",
        "First we are going to dowload the corpus and convert it to lower case letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AclKZyt4ljvH",
        "colab_type": "code",
        "outputId": "e0e6a38a-df91-4add-cae6-d5fecdd65ea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "path = keras.utils.get_file(\n",
        "    'quijote.txt',\n",
        "    origin='https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Longitud del corpus:', len(text))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud del corpus: 1038397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGq5ok-VljvL",
        "colab_type": "text"
      },
      "source": [
        "Next we will extract sentences with a partial overlapping of lenght `maxlon`, we will transform them into a one-hot vector and we will then store it in a 3D numpy array `x` whose structure will correspond to `n_sentences, maxlon, unique_characters`.\n",
        "Simultanously we will prepare a `y` array containing the corresponding targets: the one-hot vectors with the characters coming right after the extracted sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CwKc2kpljvN",
        "colab_type": "code",
        "outputId": "877adce0-0643-40f9-9f6b-f7786ffeaee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Length of extracted character sequences\n",
        "maxlon = 60\n",
        "\n",
        "# We sample a new sequence every `step` characters\n",
        "step = 3\n",
        "\n",
        "# This holds our extracted sequences\n",
        "sentences = []\n",
        "\n",
        "# This holds the targets (the follow-up characters)\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlon, step):\n",
        "    sentences.append(text[i: i + maxlon])\n",
        "    next_chars.append(text[i + maxlon])\n",
        "print('Number of sentences:', len(sentences))\n",
        "\n",
        "# List of unique characters in the corpus\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique characters:', len(chars))\n",
        "# Dictionary mapping unique characters to their index in `chars`\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "# Next, one-hot encode the characters into binary arrays.\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlon, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences: 346113\n",
            "Unique characters: 65\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcHND3tFoThr",
        "colab_type": "code",
        "outputId": "e45d93c1-ca15-49f4-d579-4d3cf8411ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.shape,y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(346113, 60, 65) (346113, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMl-xA0mljvQ",
        "colab_type": "text"
      },
      "source": [
        "## Building the network\n",
        "\n",
        "Our net is just one single `LSTM`followed by a `dense` classifier and a softmax for all the possible characters. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMXD4uQIljvR",
        "colab_type": "code",
        "outputId": "e6dc635d-ee7c-4308-9d75-316b4342560d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "from keras import layers\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(32, input_shape=(x.shape[1], y.shape[1])))\n",
        "model.add(layers.Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 32)                10112     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 46)                1518      \n",
            "=================================================================\n",
            "Total params: 11,630\n",
            "Trainable params: 11,630\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFrXfoKiljvV",
        "colab_type": "text"
      },
      "source": [
        "Since our targets are one-hot vectors, we will use `categorical_crossentropy` as loss function of our model. Use RMP prop as optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IigUQm-uljvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer = optimizers.RMSprop(lr = 0.01),loss = \"categorical_crossentropy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzvjbNQSljvf",
        "colab_type": "text"
      },
      "source": [
        "## Training the model and sampling from it\n",
        "\n",
        "\n",
        "Given a trained model and a text fragment as seed, we can generate a new text following these steps:\n",
        "\n",
        "*  Extract from the model the probability distribution of the given text given till that particular moment\n",
        "* Reweights the distribution for a certain \"temperature\"\n",
        "* Randomly sample the following character randomly following the reweighted distribution\n",
        "* Add the character at the end of the text\n",
        "\n",
        "With this code we reweights the original probability coming from the model and extract an index (sampling function)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2pe6ueGljvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperatura=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperatura\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XABGm1pljvm",
        "colab_type": "text"
      },
      "source": [
        "Finally, we have here the loop inside of which we will do the training and generate the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URJNN8M0ljvn",
        "colab_type": "code",
        "outputId": "aaf12a74-4d41-4fa6-a00a-7a2c5da5a610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "for epoch in range(1, 20):\n",
        "    print('Epoch: ', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model.fit(x, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text) - maxlon - 1)\n",
        "    generated_text = text[start_index: start_index + maxlon]\n",
        "    print('--- Generating with the following seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperatura in [0.3]:\n",
        "        print('------ Temperature:', temperatura)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(400):\n",
        "            sampled = np.zeros((1, maxlon, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperatura)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "346113/346113 [==============================] - 299s 863us/step - loss: 1.9142\n",
            "--- Generating with the following seed: \"n todo aquello que él había leído, que los caballeros and\"\n",
            "------ Temperature: 0.3\n",
            "n todo aquello que él había leído, que los caballeros andí de la pesto de la cuando el mi había de su carado de los con muspor o la me muy y a la mi has de los con caberro de la consio su amo a su la esta diso a su abrando a su abra se perde a su abra de la la verdado y al mano de la de los cual de la viero a prespor el cuento a la promo los me se había en esta que de esta de este esta de la vendió de la ma manido en esta por los caballero al me man\n",
            "Epoch:  2\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 306s 883us/step - loss: 1.7166\n",
            "--- Generating with the following seed: \" de noche, vestidos con aquellas sobrepellices, con las hach\"\n",
            "------ Temperature: 0.3\n",
            " de noche, vestidos con aquellas sobrepellices, con las hacho en la su mercente el muerta de la del que señor a la en el caballero que en la mía en la la que se en el caballero se en la mandado, y que en el mi haber que lo que la hacer a la menos, y a esto la menos, que en el cura de los la mencia de la hicho, y que en la mandas, y a la la merced que en la bien que de la que se que este que en el mondado que que en el cuerto la hacer de la hacer de la ca\n",
            "Epoch:  3\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 299s 864us/step - loss: 1.6671\n",
            "--- Generating with the following seed: \" no, desde aquí juro por el santo más bendito, de no salir\"\n",
            "------ Temperature: 0.3\n",
            " no, desde aquí juro por el santo más bendito, de no salir de mercedo, y me encuentado a la vercedo y de ser caballero de la algún de caballero de la mandere de tan con estaba de de manera y encander esta le de la de caballeros de más la mande en algún que esta de su mal de la de más la de le enturá la había en el concho en el minos de la caballeros de la mano de marcedo a encander y en el caballero en el recegura y estrerma de la ventero de provec\n",
            "Epoch:  4\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 298s 862us/step - loss: 1.6398\n",
            "--- Generating with the following seed: \"e parece sangre a este buen hombre.\n",
            "y con esto entró en el \"\n",
            "------ Temperature: 0.3\n",
            "e parece sangre a este buen hombre.\n",
            "y con esto entró en el manera al para y de sin de mi la ventura mano de la la vime y de su mano de la mieron el mano de que en la mano de la mano de su esta mi caballero de la cual en la sin amor con el para esta con el mana de la de la vida de la amante de la primera de la manos y a cuardo de quien se la caballero en está de los de sus a la alguna la la con la caballero a su acasía a la viste de esta de la la trajos \n",
            "Epoch:  5\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 299s 864us/step - loss: 1.6244\n",
            "--- Generating with the following seed: \" dolor, antes tendrás que llorar contino, si no lágrimas d\"\n",
            "------ Temperature: 0.3\n",
            " dolor, antes tendrás que llorar contino, si no lágrimas de la caballero de cual lo que lo"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " que su más mi saspor a la pasa, y la caballeros de la venta, que esta su que san su su marces de la suche, y la caballero de su sus de pasado y a la sus su parte de la venté de la de podía que si ves panta de su supo damos de la caballero de los suche a la había de su los de mi más de la descaba de su sancho sos que san su sus caballero de la la que la descand\n",
            "Epoch:  6\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 301s 870us/step - loss: 1.6130\n",
            "--- Generating with the following seed: \" y que mejor deleitan y enseñan.\n",
            "-así es -dijo el canónig\"\n",
            "------ Temperature: 0.3\n",
            " y que mejor deleitan y enseñan.\n",
            "-así es -dijo el canónigo de la luego de la dis-que este mano de la manos y más la hijos de la libro de la ventara de la recindió el caballero, por esta de la ventar de el cual con la sus que está la caballeros está de la caballero que la suerta de la vente esto de la dijo:\n",
            "-porque está de su caballero que está está a la pensaba despondió la manos de la dien que se las más y esta dien caballero del corminar de l\n",
            "Epoch:  7\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 307s 886us/step - loss: 1.6064\n",
            "--- Generating with the following seed: \"icen que tuvo la mejor mano para salar puercos que otra muje\"\n",
            "------ Temperature: 0.3\n",
            "icen que tuvo la mejor mano para salar puercos que otra mujer de caballeros de caballo por los de la cuanto de más contente a esto por los que en estos pudo la cuertante de los pería de por por conde estaba entendió de todos de mi caballero que estaba de la verse de la cara a los de caballero de mi de la que estaba de pareces de alría de los pereces de los caballero de por los caballero muchos que los hermosos de su caballeros esta encinó a la hermoso\n",
            "Epoch:  8\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 301s 869us/step - loss: 1.6010\n",
            "--- Generating with the following seed: \"el desvariado amor delante de los ojos les pone. anoche supi\"\n",
            "------ Temperature: 0.3\n",
            "el desvariado amor delante de los ojos les pone. anoche supieron de la caballero de la caballero de la caballero a la caballero de la de esta te ser los que de ser la la ver a esta contra de tanto es a la de esta de la presiento de espació a la pasado a la caballero está a la parte con la castilló a ser la puesto de espocida de de esta en la caballero de esta de la de mi venía de la caballero de caballeros de las es andidad de esta se es a la pregunter\n",
            "Epoch:  9\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 297s 859us/step - loss: 1.5959\n",
            "--- Generating with the following seed: \"adre los compró, y quiso que yo viniese por el dinero. ¿pud\"\n",
            "------ Temperature: 0.3\n",
            "adre los compró, y quiso que yo viniese por el dinero. ¿pudo la caballero y el cual los cual en el buscar de los pasado de el arto de su que lo que yo por de la cuerta de caballero de la merced de la cual la cual de la cual por esta de los caballero de la presante de la cuerda que esta la caballero de los caballeros que estaba de la cual prestore la cual de la puede que lo que es a su algún que no caballero que no por el caballero al su alguna en el amor\n",
            "Epoch:  10\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 293s 847us/step - loss: 1.5912\n",
            "--- Generating with the following seed: \"levantaré, ¡oh valeroso y esforzado caballero!, fasta que l\"\n",
            "------ Temperature: 0.3\n",
            "levantaré, ¡oh valeroso y esforzado caballero!, fasta que lo cuanto de la parte en el cualla lo que en el manera se entendiera de los aunque de ser a lo caballo de lo que en el alguno de la pasa se había a la contrando en el caballero de el de la tan entera a la caballero, y se en la descomo se entendía que se había el alguna en el anda de los caballeros que de de la que se tan de lo que esto a ella a el manera si de la cual en ella a todo a aquel mane\n",
            "Epoch:  11\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 290s 838us/step - loss: 1.5874\n",
            "--- Generating with the following seed: \"casarse vuestro amo, yo haré en ello todos mis poderíos.\n",
            "c\"\n",
            "------ Temperature: 0.3\n",
            "casarse vuestro amo, yo haré en ello todos mis poderíos.\n",
            "con lo todo de la ver a la mano de la conda que en los caballero a la la cura de la caballeros de la tratar a la ventar el ojos que los que el cura de la mano que no sin su cabal el acompaña la contra de su contentar de la curan de la cura a la proviendo al misvos en la cuenta de la cura de la caballeros con la caballero que la caballero de la mano de la cura la de la ver la cura de la había de l\n",
            "Epoch:  12\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 288s 833us/step - loss: 1.5848\n",
            "--- Generating with the following seed: \"ra, replicó don quijote, vivirás sobre la haz de la tierra\"\n",
            "------ Temperature: 0.3\n",
            "ra, replicó don quijote, vivirás sobre la haz de la tierra de la le esta en el cual a mi caballero en en esta de la caballero se le me con mi de a mi tan cuando en el cura a esta con esta en la mis que en esta en en el cual a esta de caballero de parecía con entrenos esta es aunque la male en la caballero que en el prebas de la faltad de su por ser se le había en en esta de su de se pareció a la cual que la caballero de la mano que en el cual en mi ca\n",
            "Epoch:  13\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 292s 844us/step - loss: 1.5817\n",
            "--- Generating with the following seed: \"la sepultura a un lado de una dura peña. recibiéronse los \"\n",
            "------ Temperature: 0.3\n",
            "la sepultura a un lado de una dura peña. recibiéronse los cual que la vida de la caballero en la haber en la caballero a su con la caballos de la verdad que en la cura de lo que la luer a la le mardad de mi proveñor de lo que el haber a lo que la descuyo en la cura de su espada en la le había en la ladado en la lar la para en la caballero a la del los que la llante en la haber cuando de su para a los de su le le de las caballos si la caballero que la d\n",
            "Epoch:  14\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 288s 832us/step - loss: 1.5797\n",
            "--- Generating with the following seed: \" esta verdad, que el fin de la guerra es la paz, y que en es\"\n",
            "------ Temperature: 0.3\n",
            " esta verdad, que el fin de la guerra es la paz, y que en esta osquedo y en esta en la cual a la caballería el prestas de tan la mancho más la que en su presta encindió de mi que el cual prestante en esta esto más en la cual a la prestanto que en esta son el mano de la caballeros de esto que se había en la caballero de mucha con el mano, y en el cual a mirar de tener de su marcente de su caballería que de de la cualno a la prestal de mi maña de albi\n",
            "Epoch:  15\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 289s 834us/step - loss: 1.5788\n",
            "--- Generating with the following seed: \"ido mi suerte, dijo el bachiller, suplicó a vuestra merced,\"\n",
            "------ Temperature: 0.3\n",
            "ido mi suerte, dijo el bachiller, suplicó a vuestra merced, dijo a los caballero de la caballero de como de tan a los que esto de de la mantes a la mise de mi de la todo de con la que en la caballeros de mi poco de mi la contros de le caballeros de mi había a los caballero de caballero de lo que se en la caballero esto de las cuanto y de con la prebar a dijo: de caballero de maner en los que de lo que me de caballero, y con caballero de la pasto de con e\n",
            "Epoch:  16\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 285s 825us/step - loss: 1.5778\n",
            "--- Generating with the following seed: \"nuevo delito. has hablado y apuntado muy bien, repondió don\"\n",
            "------ Temperature: 0.3\n",
            "nuevo delito. has hablado y apuntado muy bien, repondió don quijote, y de ser señor de todo señor se caballe lo que es a la para es a la su me por esta a ser señor en la pier de la había que en la cual ser de la guar en la caballero en ser a hallar que es de ser en esta es el en la caballero con el alguno de la digo que esta de su poner el pier de la pareciendo que se había se parece en la casa en la dijo en la caballero en esta es a la caballero de \n",
            "Epoch:  17\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 292s 844us/step - loss: 1.5785\n",
            "--- Generating with the following seed: \"al cabo de tres días hallaron a la antojadiza leandra en un\"\n",
            "------ Temperature: 0.3\n",
            "al cabo de tres días hallaron a la antojadiza leandra en un halla de la prebas de de la prebía de mucho a anda de la de trabo de la prebas de la cual a mi ventura de la de la mano en ver mano de alguna en la mano, que en la caballeros de la había promencia a la venta de mucho encinder de la mano de la había de la vida de la ver a caballeros que en ella me de mano de la partió con el mano, de la ventera en lo alguna de mucha la mano de más de la cabal\n",
            "Epoch:  18\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 292s 842us/step - loss: 1.5760\n",
            "--- Generating with the following seed: \"pondió a anselmo que la hablaba y jamás podía sacar della\"\n",
            "------ Temperature: 0.3\n",
            "pondió a anselmo que la hablaba y jamás podía sacar della sin a el caballero de la le me puesto de la cual manos a la cual en el amigo en la cual a la acabar en la cual en esta con el alcadado de la luego de para en el cuando de la poco a la fueron en el pendió de de la mano con la cual a la mano de los que en la cuando en el alguna me de esto la caballero le había tenía en la cuanto de ser entender de mi casa la cuanto con la caballero de caballero \n",
            "Epoch:  19\n",
            "Epoch 1/1\n",
            "346113/346113 [==============================] - 296s 856us/step - loss: 1.5759\n",
            "--- Generating with the following seed: \"oy yo, quiero que me oyas un breve cuento. has de saber que \"\n",
            "------ Temperature: 0.3\n",
            "oy yo, quiero que me oyas un breve cuento. has de saber que esta de por el recigo de al caballero en esta esta se le de la parte de se al mucho, a la verdad de la cual parece la suerta lo dice de su para se cuando a la mira de se halla en la ventero se le había de la mi armirar de la también se la parece y de esta lo cuando al parte de esta por la cual parte no esta a la la al mi amo a la caballero a la cual me de lo que el me por el mando de se esta por\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd1h1gJ3ljvr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Tasks\n",
        "\n",
        "* Use your own corpus instead of El Quijote (can be in another language)\n",
        "* Modify the loop in order to take several different temperatures (between 0.1 and 1 for instance) so that you can compare each epoch depending on the temperature\n",
        "* Train for 60 epochs\n",
        "* What do you observe in the text for the different temperatures? Which seems to be the \"best\" temperature and why?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pgtLBmZljvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f7d1e1e-da21-4e9c-e549-82f2b1378951"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rxnUhK6ljvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b943ad6-85b7-4b99-daa0-a04b3010ce3d"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "path = \"/content/drive/My Drive/LSTM/el_cuervo.txt\"\n",
        "text = open(path).read().lower()\n",
        "print('Longitud del corpus:', len(text))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud del corpus: 6686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kMlGDy7fxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "49d2e8ac-ba54-4711-cecb-087858a5f5a3"
      },
      "source": [
        "# Length of extracted character sequences\n",
        "maxlon = 60\n",
        "\n",
        "# We sample a new sequence every `step` characters\n",
        "step = 3\n",
        "\n",
        "# This holds our extracted sequences\n",
        "sentences = []\n",
        "\n",
        "# This holds the targets (the follow-up characters)\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlon, step):\n",
        "    sentences.append(text[i: i + maxlon])\n",
        "    next_chars.append(text[i + maxlon])\n",
        "print('Number of sentences:', len(sentences))\n",
        "\n",
        "# List of unique characters in the corpus\n",
        "chars = sorted(list(set(text)))\n",
        "print('Unique characters:', len(chars))\n",
        "# Dictionary mapping unique characters to their index in `chars`\n",
        "char_indices = dict((char, chars.index(char)) for char in chars)\n",
        "\n",
        "# Next, one-hot encode the characters into binary arrays.\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlon, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences: 2209\n",
            "Unique characters: 46\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCVntIJY7t30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a19fe9e-5984-4bf0-e748-c2ee93c54c5a"
      },
      "source": [
        "print(x.shape,y.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2209, 60, 46) (2209, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww291eIM7xSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "9e643286-508c-43be-f766-a5c530620eea"
      },
      "source": [
        "model_cuervo = keras.models.Sequential()\n",
        "model_cuervo.add(layers.LSTM(128, input_shape=(x.shape[1], y.shape[1])))\n",
        "model_cuervo.add(layers.Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model_cuervo.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 32)                10112     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 46)                1518      \n",
            "=================================================================\n",
            "Total params: 11,630\n",
            "Trainable params: 11,630\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-TbcaKL73Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cuervo.compile(optimizer = optimizers.RMSprop(lr = 0.01),loss = \"categorical_crossentropy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxAMKW-W7-Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "for epoch in range(1, 60):\n",
        "    print('Epoch: ', epoch)\n",
        "    # Fit the model for 1 epoch on the available training data\n",
        "    model_cuervo.fit(x, y,\n",
        "              batch_size=128,\n",
        "              epochs=1)\n",
        "\n",
        "    # Select a text seed at random\n",
        "    start_index = random.randint(0, len(text) - maxlon - 1)\n",
        "    generated_text = text[start_index: start_index + maxlon]\n",
        "    print('--- Generating with the following seed: \"' + generated_text + '\"')\n",
        "\n",
        "    for temperatura in np.arange(0.1,1.0,0.1):\n",
        "        print('------ Temperature:', temperatura)\n",
        "        sys.stdout.write(generated_text)\n",
        "\n",
        "        # We generate 400 characters\n",
        "        for i in range(200):\n",
        "            sampled = np.zeros((1, maxlon, len(chars)))\n",
        "            for t, char in enumerate(generated_text):\n",
        "                sampled[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model_cuervo.predict(sampled, verbose=0)[0]\n",
        "            next_index = sample(preds, temperatura)\n",
        "            next_char = chars[next_index]\n",
        "\n",
        "            generated_text += next_char\n",
        "            generated_text = generated_text[1:]\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}