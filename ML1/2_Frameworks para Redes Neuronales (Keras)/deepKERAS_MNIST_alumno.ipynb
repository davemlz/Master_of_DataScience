{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica KERAS en R con el dataset MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalar KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KERAS es una librería para la construcción de redes neuronales muy versátil y ampliamente utilizada por la comunidad de deep learning. Aunque fue diseñada originalmente para python en los últimos años se ha desarrollado una interfaz de KERAS en R para que sus usuarios también puedan beneficiarse de la potencia de KERAS. Información sobre por qué usar KERAS como librería principal para el diseño de redes neuronales puede encontrarse en el siguinte link: https://keras.rstudio.com/articles/why_use_keras.html . En cuanto a la instalación hay que hacer lo siguiente: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ir a la terminal y teclear:  pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/Dave Mont/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n",
      "\n",
      "also installing the dependencies 'rappdirs', 'config', 'reticulate', 'tensorflow', 'tfruns'\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'rappdirs' successfully unpacked and MD5 sums checked\n",
      "package 'config' successfully unpacked and MD5 sums checked\n",
      "package 'reticulate' successfully unpacked and MD5 sums checked\n",
      "package 'tensorflow' successfully unpacked and MD5 sums checked\n",
      "package 'tfruns' successfully unpacked and MD5 sums checked\n",
      "package 'keras' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Dave Mont\\AppData\\Local\\Temp\\RtmpoVli0C\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'keras' was built under R version 3.6.2\"\n",
      "Warning message in normalizePath(path.expand(path), winslash, mustWork):\n",
      "\"path[1]=\"C:\\Users\\Dave Mont\\Anaconda3\\envs\\Estadistica/python.exe\": El sistema no puede encontrar el archivo especificado\"\n",
      "Warning message in normalizePath(path.expand(path), winslash, mustWork):\n",
      "\"path[1]=\"C:\\Users\\Dave Mont\\Anaconda3\\envs\\Estadistica/python.exe\": El sistema no puede encontrar el archivo especificado\"\n",
      "Warning message in normalizePath(path.expand(path), winslash, mustWork):\n",
      "\"path[1]=\"C:\\Users\\Dave Mont\\Anaconda3\\envs\\Estadistica/python.exe\": El sistema no puede encontrar el archivo especificado\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installation complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"keras\")\n",
    "library(keras)\n",
    "install_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: keras\n",
      "\n",
      "Warning message:\n",
      "\"package 'keras' was built under R version 3.6.2\"\n"
     ]
    }
   ],
   "source": [
    "require(keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construccion de un modelo de KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos maneras de construir un modelo en KERAS: el modelo secuencial y el modelo funcional. En el primer caso la red es una secuencia lineal de capas, mientras que el segundo caso permite una elaboración de redes con topologías más complejas (como por ejemplo redes acícliclas). Los pasos para construir una red son:\n",
    "\n",
    "1- Diseñar la arquitectura de la red (ya sea mediante la manera secuencial o funcional).\n",
    "\n",
    "2- Compilar el modelo (aqui se incluye la seleccion del algoritmo de aprendizaje y la funcion de coste a minimizar).\n",
    "\n",
    "3- En este paso se introduce el dataset, la separación entre validacion y train, nº de epocas. En resumen se entrena la arquiterctura del paso 1 con el algoritmo seleccionado en el paso 2.\n",
    "\n",
    "4- Utilizar el modelo para predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 El modelo secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model <- keras_model_sequential() \n",
    "# model %>% \n",
    "#   layer_dense(units = neuronas ocultas 1, input_shape = neuronas de entrada, activation = \"sigmoid\") %>% # Primera capa oculta\n",
    "#   layer_dense(units = neuronas ocultas 2, activation = \"sigmoid\") %>% # Segunda capa oculta\n",
    "#   layer_dense(units = neuronas de salida , activation = \"sigmoid\") # capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 El modelo funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = layer_input(shape = dim(xT)[-1])\n",
    "# x = inputs\n",
    "# l1 = layer_dense(x,units = neuronas ocultas 1, activation = \"sigmoid\")\n",
    "# l2 = layer_dense(l1,units = neuronas ocultas 2, activation = \"sigmoid\")\n",
    "# outputs = layer_dense(l1,units = neuronas de salida, activation = \"sigmoid\")\n",
    "\n",
    "# model <- keras_model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Compilar el modelo y entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model %>% compile(optimizer = optimizer_adam(lr = learning_rate), \n",
    "#                     loss = \"mse\")\n",
    "\n",
    "#  model %>% fit(xT, yT, epochs = epochs, batch_size = 100, validation_split = 0.1, callbacks = callbacks, verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction <- model$predict(xt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construir una red neuronal para el dataset MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cargar el dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read.csv(\"MNIST_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in normalizePath(path.expand(path), winslash, mustWork):\n",
      "\"path[1]=\"C:\\Users\\Dave Mont\\Anaconda3\\envs\\Estadistica/python.exe\": El sistema no puede encontrar el archivo especificado\"\n"
     ]
    }
   ],
   "source": [
    "mnist = dataset_mnist()\n",
    "x_train = mnist$train$x\n",
    "y_train = mnist$train$y\n",
    "x_test = mnist$test$x\n",
    "y_test = mnist$test$y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Preprocesar los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalización, adecuar las matrices con las columnas apropiadas (por ejemplo, 784 en la entrada) ...\n",
    "\n",
    "\n",
    "## matriz de salida (neuronas de salida)\n",
    "\n",
    "\n",
    "## matriz de entrada (neuronas de entrada)\n",
    "\n",
    "\n",
    "## normalizar/escalar\n",
    "\n",
    "\n",
    "## train/test (los primeros 30000 son train y el resto test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Construir una red con estructura 784-100-100-10 mediante el modelo secuencial y entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCRIBE AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Construir una red con estructura 784-100-100-10 mediante el modelo funcional y entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCRIBE AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Predecir en el conjunto de test y validar para el modelo funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICE AQUI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora valida calculando el AUC por dígito y el accuracy tal y como visteis en la práctica de KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"verification\") para importar la funcion roc.area()\n",
    "\n",
    "## AUC\n",
    "\n",
    "\n",
    "## Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Reponde a las siguientes preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - ¿Para qué número obtengo el AUC más alto? ¿y para cuál el más bajo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCRIBE AQUÍ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Construir una red con estructura 784-50-25-50-10, ¿qué es lo que sucede en el entrenamiento?¿por qué no funciona bien?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCRIBE AQUÍ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- ¿Crees que para problemas de clasificación es apropiado minimizar el mean squared error? Construye una red minimizando el categorical cross-entropy, tal que en compile(loss = \"categorical_crossentropy\") y vuelve a calcular los índices de validación...¿ves alguna diferencia con respecto a cuando se entrenó minimizando el \"mse\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENA AQUÍ CON CATEGORICAL CROSSENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICE Y VALIDA AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Early-Stopping y como guardar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las redes neuronales hay muchos parámetros y por tanto en muchas ocasiones es necesario adoptar medidas de regularización como el early-stopping. El early-stopping consiste en parar el entrenamiendo cuando se cumpla un criterio como los siguientes:\n",
    "\n",
    "    1- Que la diferencia del error entre el dataset de train y el dataset de validación no supere un mínimo\n",
    "    \n",
    "    2- Cuando el error de validación deje de disminuir.\n",
    "\n",
    "La manera de implementarlo en KERAS es a través de los callbacks. Los callbacks se refieren a funciones que solo aplican durante el entrenamiento (por ejemplo, el early-stopping solo tiene sentido mientras el modelo entrena, cuando ya está entrenado no hay nada que parar). El registro completo de callbacks definidos en KERAS puede verse en el siguiente link: https://keras.io/callbacks/  . En esta clase vamos a ver dos funciones pertenecientes a los callbacks: el callback del early-stopping y el callback de guardar el modelo en cada época."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.1 Callback del early-stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = list(callback_early_stopping(patience = patience))\n",
    "\n",
    "# inputs = layer_input(shape = dim(xT)[-1])\n",
    "# x = inputs\n",
    "# l1 = layer_dense(x,units = neuronas ocultas 1, activation = \"sigmoid\")\n",
    "# l2 = layer_dense(l1,units = neuronas ocultas 2, activation = \"sigmoid\")\n",
    "# outputs = layer_dense(l2,units = neuronas de salida, activation = \"sigmoid\")\n",
    "\n",
    "# model <- keras_model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "#  model %>% compile(optimizer = optimizer_sgd(lr = learning_rate), \n",
    "#                     loss = \"mse\") \n",
    "                     \n",
    "\n",
    "#  model %>% fit(xT, yT, epochs = epochs, batch_size = 100, validation_split = 0.1, callbacks = callbacks, verbose = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.2 Callback de guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = list(callback_model_checkpoint(filepath='filename.h5'))\n",
    "\n",
    "# inputs = layer_input(shape = dim(xT)[-1])\n",
    "# x = inputs\n",
    "# l1 = layer_dense(x,units = neuronas ocultas 1, activation = \"sigmoid\")\n",
    "# l2 = layer_dense(l1,units = neuronas ocultas 2, activation = \"sigmoid\")\n",
    "# outputs = layer_dense(l2,units = neuronas de salida, activation = \"sigmoid\")\n",
    "\n",
    "# model <- keras_model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "#  model %>% compile(optimizer = optimizer_sgd(lr = learning_rate), \n",
    "#                     loss = \"mse\") \n",
    "\n",
    "\n",
    "#  model %>% fit(xT, yT, epochs = epochs, batch_size = 100, validation_split = 0.1, callbacks = callbacks, verbose = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.3 Guardar únicamente el mejor modelo de acuerdo al criterio del early-stopping... y cargarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = list(callback_early_stopping(patience = patience), callback_model_checkpoint(filepath=paste0('filename.h5'), monitor='val_loss', save_best_only=TRUE))\n",
    "\n",
    "# inputs = layer_input(shape = dim(xT)[-1])\n",
    "# x = inputs\n",
    "# l1 = layer_dense(x,units = neuronas ocultas 1, activation = \"sigmoid\")\n",
    "# l2 = layer_dense(l1,units = neuronas ocultas 2, activation = \"sigmoid\")\n",
    "# outputs = layer_dense(l2,units = neuronas de salida, activation = \"sigmoid\")\n",
    "\n",
    "# model <- keras_model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "#  model %>% compile(optimizer = optimizer_sgd(lr = learning_rate), \n",
    "#                     loss = \"mse\") \n",
    "\n",
    "\n",
    "#  model %>% fit(xT, yT, epochs = epochs, batch_size = 100, validation_split = 0.1, callbacks = callbacks, verbose = 1) \n",
    "\n",
    "# k_clear_session()\n",
    "\n",
    "# load_model_hdf5(filepath = \"filename.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.4 Responde a las siguientes preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena el mismo modelo con y sin early-stopping (sin early-stopping quiere decir que entreneis 200 épocas, por ejemplo). Cargalo y calcula el AUC.\n",
    "\n",
    "    1- ¿qué modelo obtiene un AUC mayor para todos los números, el del early-stopping o el que no, en el dataset de TRAIN?\n",
    "    \n",
    "    2- ¿qué modelo obtiene un AUC mayor para todos los números, el del early-stopping o el que no, en el dataset de TEST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENA AQUI SIN EARLY-STOPPING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENA AQUI CON EARLY-STOPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREDICCION EN EL TRAIN CON LOS DOS MODELOS (RECORDAD QUE EL DE EARLY-STOPPING HAY QUE CARGARLO)\n",
    "\n",
    "## AUC\n",
    "\n",
    "\n",
    "## Accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREDICCION EN EL TEST CON LOS DOS MODELOS (RECORDAD QUE EL DE EARLY-STOPPING HAY QUE CARGARLO)\n",
    "\n",
    "## AUC\n",
    "\n",
    "\n",
    "## Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Diseña una arquitectura original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Un ejemplo de arquitectura atípica serian las deep residual networks: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"deepresidual.png\" width= \"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCRIBIR LA RED DE PALABRA AQUÍ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTAR LA RED AQUÍ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
