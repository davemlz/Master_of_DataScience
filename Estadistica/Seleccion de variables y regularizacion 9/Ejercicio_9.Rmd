---
title: "Ejercicio 9"
output:
  html_document:
    df_print: paged
---

## David Montero Loaiza

# Ejercicio de regularización

En este ejercicio practicamos los fundamentos de la regularización L2 (ridge), en la que la minimización de la RSS con penalización tiene una forma explícita sencilla
$$ (X^tX+\lambda I)\beta = X^ty$$
Utilizaremos los datos de una muestra sintética para conocer el verdadero modelo que tratamos de ajustar. Para ello:

1. Escribe una función de R que reciba como input un vector `x` con la variable dependiente, un vector de parámetros ```alpha``` que contenga los coeficientes de un polinomio y una ```sigma```; y que devuelva el vector dependiente que siga la ley polinomial dada con PDF gaussiana y sigma (desviación estándar) dada. 

```{r}
generate_X = function(x,gpoly){
  
  X = rep(1,length(x))
  
  for(i in 1:gpoly){
    
    X = cbind(X,x^i)
    
  }
  
  return(X)
  
}

genY = function(x,alpha,sigma){
  
  gpoly = length(alpha) - 1
  
  X = generate_X(x,gpoly)
  
  y = (X %*% alpha) + rnorm(x,0,sigma)
  
}
```

2. Construye un vector de 40 elementos distribuido uniformemente entre [-3, 3]. Úsalo con la función anterior, el polinomio: $x^3 + 2 x^2 - x - 2$ y $\sigma = 4$. Representa los datos resultantes.

```{r}
x = runif(40,-3,3)
alpha = c(-2,-1,2,1)
sigma = 4

y = genY(x,alpha,sigma)

plot(x,y)
```

3. Calcula el valor mínimo de la función de coste (_loss_, RSS) para el caso en que hacemos un ajuste con una recta (dos parámetros), una parábola (tres parámetros), 4, 5, 6 y 7 parámetros, usando los primeros 20 puntos. Con los valores que hacen mínimo el RSS para la muestra de entrenamiento, calcula el RSS para los siguientes 20 puntos. Pinta los resultados en función del número de parámetros para ambos casos.

```{r}
loss_min = function(X,y){
  
  a = solve(t(X) %*% X) %*% t(X) %*% y
  
  return(a)
  
}

xtrain = x[1:20]
ytrain = y[1:20]

alpha2 = loss_min(generate_X(xtrain,1),ytrain)
alpha3 = loss_min(generate_X(xtrain,2),ytrain)
alpha4 = loss_min(generate_X(xtrain,3),ytrain)
alpha5 = loss_min(generate_X(xtrain,4),ytrain)
alpha6 = loss_min(generate_X(xtrain,5),ytrain)
alpha7 = loss_min(generate_X(xtrain,6),ytrain)
```

4. Escribe una función de R que encuentre el mínimo de la función de coste para el caso de regularización L2. El parámetro lambda será pasado como input. Utilízala para estimar las curvas que mejor ajustan para los casos:
  * 3 parámetros, lambda=0
  * 10 parámetros, lambda=0
  * 10 parámetros, lambda=1000

Representa todas las curvas juntas y escribe tus conclusiones.

```{r}

```

5. Utiliza la función anterior para representar el valor de los parámetros del modelo en función de $\lambda$. Prueba a representar la evolución de los coeficientes de un modelo de 11 parámetros.

```{r}

```
