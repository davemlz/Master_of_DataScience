---
title: "Ejercicio 4"
output:
  html_document:
    df_print: paged
---

## David Montero Loaiza

### Problema 1

Crea una función que genere dos muestras que se distribuyen según dos gaussianas distintas. La función recibirá como valores de entrada: el número N de puntos a generar para cada categoría, y mu1, sigma1, mu2, sigma2 que son los correspondientes parámetros de las dos gaussianas. Como output devolverá un valor con longitud 2N que contenga la muestra x generada, y otro vector de longitud 2N que contenga 0 o 1 en función de la categoría asociada a ese elemento.

```{r}
generate_samples = function(N,mu1,sigma1,mu2,sigma2){
  
  # GAUSIANAS
  x1 = rnorm(N,mu1,sigma1)
  x2 = rnorm(N,mu2,sigma2)
  x = c(x1,x2)
  
  # OUTPUTS 1 Y 0
  y1 = rep(0,N)
  y2 = rep(1,N)
  y = c(y1,y2)
  
  # GUARDAR EN DATA FRAME
  df = data.frame(x,y)
  
  return(df)
  
}
```

### Problema 2

Crea una función que calcule el valor de la sigmoide para un valor de entrada Z.

```{r}
sigmoid = function(Z){
  
  # RETORNAR VALOR DE SIGMOIDE
  return(1/(1 + exp(-Z)) )
  
}
```

### Problema 3

Crea una función que calcule el valor de la función de Loss y que reciba como entrada "x" e "y" y los parámetros del modelo que vamos a asumir: z = a + b x (es decir, a y b).

```{r}
loss = function(x,y,a,b){
  
  # VALOR Z PARA SIGMOIDE
  Z = a + b*x
  
  # CALCULAR SIGMOIDE
  s = sigmoid(Z)
  
  # CALCULAR VALOR DE LOSS
  loss = -sum(y * log(s) + (1 - y) * log(1 - s))/length(x)
  
  # RETORNAR LOSS
  return(loss)
  
}
```

### Problema 4

Crea una función que devuelva el gradiente de la función de Loss y que reciba como entrada "x" e "y" y los parámetros (a, b) del modelo que vamos a asumir.

```{r}
# FUNCION DE GRADIENTE PARA UN POLINOMIO DE GRADO 1
gradient = function(x,y,a,b){
  
  # TAMANO DE X
  N = length(x)
  
  # SIGMOIDE
  s = sigmoid(a + b*x)
  
  # GRADOS DEL POLINOMIO
  g = 0:1
  
  # FUNCION PARA CALCULAR EL GRADIENTE SEGUN EL GRADO DEL POLINOMIO
  f = function(g) -sum((s - y) * -(x^g))/N
  
  # CALCULAR EL GRADIENTE SEGUN EL GRADO DEL POLINOMIO
  grad = sapply(g,f)
  
  return(grad)
  
}
```

### Problema 5

Generar un par de vectores "x", "y" con N = 100, mu1 = 2, mu2 = 6, sigma1 = 1 y sigma2 = 1.

```{r}
N = 100
mu1 = 2
mu2 = 6
sigma1 = 1
sigma2 = 1

xy = generate_samples(N,mu1,sigma1,mu2,sigma2)

x = xy$x
y = xy$y
```

### Problema 6

Calcular la función de coste y el gradiente para (a = 0, b = 0). Actualizar los valores de a y b de manera que (a, b)_nuevos = (a, b)_viejos + lambda * gradiente. Repite 3 o 4 cuatro veces y observa los valores de la función de coste. Intenta encontrar el mínimo aproximadadamente. Interpreta los resultados.

```{r}
# VALORES INICIALES DE LOS PARAMETROS DE ALPHA
a = 0
b = 0

# PRUEBA COM LAMBDA DE -1 Y 4 ITERACIONES
lambda = -1
iterations = 4

# FUNCION PARA APROXIMAR MINIMO DE LOSS
get_alpha_loss = function(x,y,a,b,lambda,iterations){
  
  # VECTOR PARA GUARDAR VALORES DE LOSS POR CADA ITERACION
  loss_vector = NULL

  # ITERACIONES PARA ACTUALIZAR ALPHA
  for(i in 1:iterations){
  
    # GUARDAR VALORES DE LOSS
    loss_vector = c(loss_vector,loss(x,y,a,b))
    
    # CALCULAR GRADIENTE
    grad = gradient(x,y,a,b)
    
    # ACTUALIZAR ALPHA
    a = a + lambda * grad[1]
    b = b + lambda * grad[2]
  
  }
  
  # GUARDAR EN LISTA PARA RETORNAR
  l = list("a" = a,
           "b" = b,
           "loss" = loss_vector[length(loss_vector)],
           "loss_vector" = loss_vector,
           "iterations" = iterations)
  
  return(l)
  
}

# APROXIMA MINIMO DE LOSS PARA LAMBDA -1 Y 4 ITERACIONES
al = get_alpha_loss(x,y,a,b,lambda,iterations)

# PLOT EN DOS COLUMNAS
par(mfrow = c(1,2))

# PLOT DE VALOR DE LOSS EN FUNCION DE LAS ITERACIONES
plot(1:al$iterations,al$loss_vector,main = "Valor de loss (lambda = -1)",xlab = "Iteraciones",ylab = "Loss")
  
# PLOT DE LOS PUNTOS Y LA SIGMOIDE AJUSTADA
plot(x,y,main = "Sigmoide")
curve(sigmoid(al$a + al$b*x),add = TRUE,col = "red")
```

Usando un valor de lambda = -1 se puede apreciar que el valor de la función de coste da saltos muy grandes, fluctuando entre menores y mayores valores de loss y la sigmoide no se ajusta correctamente a los datos después de 4 iteraciones. En el siguiente código se procede a usar un lambda = -0.5 y un total de 50 iteraciones.

```{r}
# PRUEBA COM LAMBDA DE -0.5 Y 50 ITERACIONES
lambda = -0.5
iterations = 50

# APROXIMA MINIMO DE LOSS PARA LAMBDA -0.5 Y 50 ITERACIONES
al = get_alpha_loss(x,y,a,b,lambda,iterations)

# PLOT EN DOS COLUMNAS
par(mfrow = c(1,2))

# PLOT DE VALOR DE LOSS EN FUNCION DE LAS ITERACIONES
plot(1:al$iterations,al$loss_vector,main = "Valor de loss (lambda = -0.5)",xlab = "Iteraciones",ylab = "Loss")

# PLOT DE LOS PUNTOS Y LA SIGMOIDE AJUSTADA
plot(x,y,main = "Sigmoide")
curve(sigmoid(al$a + al$b*x),add = TRUE,col = "red")
```

Con un valor de lambda = -0.5 y un total de 50 iteraciones el valor de la función de coste empieza a disminuir sin fluctuaciones entre mayores y menores valores de loss, sin embargo, la sigmoide aún no se ajusta correctamente a los datos. En el siguiente código se aumentará el número de iteraciones a 200

```{r}
# PRUEBA COM LAMBDA DE -0.5 Y 1000 ITERACIONES
lambda = -0.5
iterations = 200

# APROXIMA MINIMO DE LOSS PARA LAMBDA -0.5 Y 200 ITERACIONES
al = get_alpha_loss(x,y,a,b,lambda,iterations)

# PLOT EN DOS COLUMNAS
par(mfrow = c(1,2))

# PLOT DE VALOR DE LOSS EN FUNCION DE LAS ITERACIONES
plot(1:al$iterations,al$loss_vector,main = "Valor de loss (lambda = -0.5)",xlab = "Iteraciones",ylab = "Loss")

# PLOT DE LOS PUNTOS Y LA SIGMOIDE AJUSTADA
plot(x,y,main = "Sigmoide")
curve(sigmoid(al$a + al$b*x),add = TRUE,col = "red")
```

En el siguente código se hace una prueba en que se evalúan diferentes lambdas (-1,-0.75,-0.5,-0.25) con 200 iteraciones.

```{r}
# PRUEBA COM DIFERENTES LAMBDAS
lambda = seq(-1,-0.25,0.25)
iterations = 200

# APROXIMA MINIMO DE LOSS PARA LOS DIFERENTES LAMBDAS EN 200 ITERACIONES
al = lapply(lambda,get_alpha_loss,x = x,y = y,a = a,b = b,iterations = iterations)

# PLOT EN DOS COLUMNAS
par(mfrow = c(1,2))

# PLOT DE VALOR DE LOSS EN FUNCION DE LAS ITERACIONES PAA DISTINTOS LAMBDAS
plot(1:al[[1]]$iterations,
     al[[1]]$loss_vector,
     type = "l",
     col = "black",
     main = "Valor de loss",
     xlab = "Iteraciones",
     ylab = "Loss")

lines(1:al[[2]]$iterations,al[[2]]$loss_vector,type = "l",col = "red")
lines(1:al[[3]]$iterations,al[[3]]$loss_vector,type = "l",col = "blue")
lines(1:al[[4]]$iterations,al[[4]]$loss_vector,type = "l",col = "green")

legend("topright",
       legend = c(-1,-0.75,-0.5,-0.25),
       col = c("black","red","blue","green"),
       lwd = 1,
       title = "Lambda")

# PLOT DE LOS PUNTOS Y LA SIGMOIDE AJUSTADA
plot(x,y,main = "Sigmoide")
curve(sigmoid(al[[1]]$a + al[[1]]$b*x),add = TRUE,col = "black")
curve(sigmoid(al[[2]]$a + al[[2]]$b*x),add = TRUE,col = "red")
curve(sigmoid(al[[3]]$a + al[[3]]$b*x),add = TRUE,col = "blue")
curve(sigmoid(al[[4]]$a + al[[4]]$b*x),add = TRUE,col = "green")
```

Para este caso, con valores menores valores de lambda (-1) se alcanza más rápido un menor valor de loss que utilizando lambdas más altos (-0.25), aunque en las primeras iteraciones haya más fluctuaciones. Con 200 iteraciones se logra aproximar al mínimo valor de loss. Sin embargo, se acercará más aumentando el número de iteraciones.